{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install \"cleanvision[huggingface]\"\n",
    "!pip install pyod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Import PyTorch\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "from cleanvision import Imagelab\n",
    "from PIL import Image\n",
    "import requests\n",
    "import torch\n",
    "import cv2\n",
    "import imagehash\n",
    "\n",
    "\n",
    "# Import torchvision\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "# Import matplotlib for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# prompt: download fashion mnist from torch vision\n",
    "\n",
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# add transformations to above so that it lies between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Plot more images\n",
    "torch.manual_seed(42)\n",
    "fig = plt.figure(figsize=(9, 9))\n",
    "rows, cols = 4, 4\n",
    "for i in range(1, rows * cols + 1):\n",
    "    random_idx = torch.randint(0, len(train_data), size=[1]).item()\n",
    "    img, label = train_data[random_idx]\n",
    "    fig.add_subplot(rows, cols, i)\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "    plt.title(train_data.classes[label])\n",
    "    plt.axis(False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=32,shuffle=True)\n",
    "train_features_batch, train_labels_batch = next(iter(train_dataloader))\n",
    "\n",
    "print(f\"Features Batch Size {train_features_batch.shape}\")\n",
    "print(f\"Labels Batch Size {train_labels_batch.shape}\")\n",
    "print(f\"Length of train dataloader: {len(train_dataloader)} batches of 32\")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "test_dataloader = DataLoader(test_data, batch_size=32,shuffle=False)\n",
    "test_features_batch, test_labels_batch = next(iter(test_dataloader))\n",
    "\n",
    "print(f\"Features Batch Size {test_features_batch.shape}\")\n",
    "print(f\"Labels Batch Size {test_labels_batch.shape}\")\n",
    "print(f\"Length of train dataloader: {len(test_dataloader)} batches of 32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def data_cleaner(ims):\n",
    "\n",
    "    imagelab = Imagelab(hf_dataset=ims, image_key=\"image\")\n",
    "    issue_df = imagelab.issues\n",
    "\n",
    "    # handling images with low information\n",
    "    images_with_low_information = issue_df[issue_df['is_low_information_issue'] == True].reset_index()[['index','low_information_score']]\n",
    "    img_index_with_low_information = images_with_low_information['index']\n",
    "\n",
    "\n",
    "    # handling dark images\n",
    "    dark_images = issue_df[issue_df['is_dark_issue'] == True].reset_index()[['index','dark_score']]\n",
    "    dark_img_index = dark_images['index']\n",
    "\n",
    "\n",
    "    # handling duplicate images\n",
    "    duplicate_images = issue_df[issue_df['is_near_duplicates_issue'] == True].reset_index()[['index','near_duplicates_score']]\n",
    "    duplicate_images_index = []\n",
    "    for i in imagelab.info[\"near_duplicates\"][\"sets\"]:\n",
    "    for j,counter in zip(i,range(0,len(i))):\n",
    "        if counter == 0:\n",
    "        continue\n",
    "        else:\n",
    "        duplicate_images_index.append(j)\n",
    "\n",
    "    # appending all the images to be removed from dataset\n",
    "    img_index_to_remove = list(set(list(img_index_with_low_information) + list(dark_img_index) + list(duplicate_images_index)))\n",
    "\n",
    "    return img_index_to_remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dataset_dict = load_dataset(\"zalando-datasets/fashion_mnist\")\n",
    "\n",
    "# train dataset\n",
    "train_data = dataset_dict['train']\n",
    "train_images = np.array(train_data['image'])\n",
    "train_labels = np.array(train_data['label'])\n",
    "\n",
    "# test dataset\n",
    "test_data = dataset_dict['test']\n",
    "test_images = np.array(test_data['image'])\n",
    "test_labels = np.array(test_data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "to_remove = data_cleaner(train_data)\n",
    "\n",
    "\n",
    "# new image list\n",
    "reduced_train_images = []\n",
    "reduced_train_labels = []\n",
    "\n",
    "for counter, im, label in zip(range(len(train_images)), train_images, train_labels):\n",
    "    if counter in img_index_to_remove:\n",
    "        continue\n",
    "    else:\n",
    "        reduced_train_images.append(im)\n",
    "        reduced_train_labels.append(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling and Training FFNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class FFNN_Model(nn.Module):\n",
    "\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=input_shape, out_features=hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_units, out_features=output_shape),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.layer_stack(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "model = FFNN_Model(input_shape=784, hidden_units=10, output_shape=10 ).to(device)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "next(model.parameters()).device # check model device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=model.parameters(),lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def accuracy_fn(y_true, y_pred):\n",
    "    return (torch.eq(y_true, y_pred).sum().item() / len(y_pred)) * 100\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "for epoch in tqdm(range(3)): # running for 3 epochs\n",
    "\n",
    "    print(f\"Epoch: {epoch}\\n-------\")\n",
    "\n",
    "    '''\n",
    "    TRAINING\n",
    "    '''\n",
    "    train_loss, train_acc = 0, 0\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        y_pred = model(X) #Forward pass\n",
    "\n",
    "        loss = loss_fn(y_pred, y) # Calculate loss (per batch)\n",
    "        acc = accuracy_fn(y_true=y,y_pred=y_pred.argmax(dim=1))\n",
    "\n",
    "        train_loss += loss # accumulatively add up the loss per epoch\n",
    "        train_acc += acc # Go from logits -> pred labels\n",
    "\n",
    "        optimizer.zero_grad() # Optimizer zero grad\n",
    "        loss.backward() # Loss backward\n",
    "        optimizer.step() # Optimizer step\n",
    "\n",
    "        # Print out how many samples have been seen\n",
    "        if batch % 400 == 0:\n",
    "            print(f\"Looked at {batch * len(X)}/{len(train_dataloader.dataset)} samples\")\n",
    "\n",
    "    # Divide total train loss by length of train dataloader (average loss per batch per epoch)\n",
    "    train_loss /= len(train_dataloader)\n",
    "    train_acc /= len(train_dataloader)\n",
    "    print(f\"Train loss: {train_loss:.5f} | Train accuracy: {train_acc:.2f}%\")\n",
    "\n",
    "    '''\n",
    "    TESTING\n",
    "    '''\n",
    "    test_loss, test_acc = 0, 0\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X, y in test_dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            test_pred = model(X) # Forward pass\n",
    "\n",
    "            loss = loss_fn(test_pred, y)\n",
    "            acc = accuracy_fn(y_true=y,y_pred=test_pred.argmax(dim=1))\n",
    "\n",
    "            test_loss += loss\n",
    "            test_acc += acc\n",
    "\n",
    "        # Calculations on test metrics need to happen inside torch.inference_mode()\n",
    "        test_loss /= len(test_dataloader)\n",
    "        test_acc /= len(test_dataloader)\n",
    "\n",
    "    print(f\"Test loss: {test_loss:.5f}  | Test acc: {test_acc:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling and Training ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling and Training Vision Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
