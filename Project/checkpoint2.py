# -*- coding: utf-8 -*-
"""checkpoint2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/github/khetansarvesh/MSML_602/blob/main/Project/checkpoint2.ipynb

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/khetansarvesh/MSML_602/blob/main/Project/checkpoint2.ipynb)

# **Installing and Importing Libraries**
"""

!pip install -U pip
!pip install "cleanvision[huggingface]"
!pip install pyod
# !pip install transformers

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datasets import load_dataset, concatenate_datasets
from cleanvision import Imagelab
from PIL import Image
import requests
# from transformers import CLIPProcessor, CLIPModel
import torch
import cv2
from pyod.models.knn import KNN
import imagehash
from sklearn.decomposition import PCA

"""# **Importing Dataset from Hugging Face**"""

dataset_dict = load_dataset("zalando-datasets/fashion_mnist")
train_images = np.array(dataset_dict['train']['image'])
train_labels = np.array(dataset_dict['train']['label'])

# showing some sample images
for im in range(5):
  plt.imshow(train_images[im])
  plt.show()

"""# **Data Processing and Cleaning**

Instead of manually creating functions for each type of potential issue in the dataset for example Low Information / Illumination Issue / Blurry Images / ....we will use [IMAGELAB](https://github.com/cleanlab/cleanvision) LIBRARY which does all of this for use at once
"""

imagelab = Imagelab(hf_dataset=dataset_dict['train'], image_key="image")
imagelab.find_issues()

imagelab.issue_summary

# Following dataset helps us to view information about each image, such as what types of issues it exhibits and its quality score with respect to each type of issue.
issue_df = imagelab.issues
issue_df

"""## Check for Images with Low Information in dataset
There are many ways to check if the image contains low information or not eg using entropy value or using variance across different axes of the image.
"""

images_with_low_information = issue_df[issue_df['is_low_information_issue'] == True].reset_index()[['index','low_information_score']]

images_with_low_information

# seeing some sample images with low information
for score, i in zip(images_with_low_information['low_information_score'], images_with_low_information['index']):
  if score < 0.12:
    plt.imshow(train_images[i])
    print(score)
    plt.show()

imagelab.visualize(issue_types=["low_information"], num_images=20)

img_index_with_low_information = images_with_low_information['index']

'''
Following is a way to manually calculate entropy value of an image to check for low information issue.
This method suggests that there are no images with low information in our dataset.
I am not sure what method does the Imagelab library use to check for low information issue.
'''

# def calculate_entropy(image):
#     histogram = cv2.calcHist([image], [0], None, [256], [0, 256])
#     histogram = histogram / np.sum(histogram)
#     entropy = -np.sum(histogram * np.log2(histogram + np.finfo(float).eps))
#     return entropy

# entropies = [calculate_entropy(image) for image in train_images]
# threshold = 0.5  # Adjust this threshold as needed
# low_entropy_images = [image for image, entropy in zip(train_images, entropies) if entropy < threshold]

# for image in low_entropy_images:
#     plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
#     plt.show()

"""## Check for Blurry Images in dataset
There are many ways to check blurriness in an image like laplacian and fourier transform.

Imagelab library suggests that are are no blurry images in our dataset, let's check that manually too by implementing our own version to check for blurry images.
"""

is_blurry_image = [cv2.Laplacian(image, cv2.CV_64F).var()<1000 for image in train_images]

for i in is_blurry_image:
  if i == True:
    print(i)

"""Hence this shows that there are no blurry images in our dataset

## Check for Light / Dark Images in dataset
Here we first identify if there are too dark or too light images in our dataset
"""

dark_images = issue_df[issue_df['is_dark_issue'] == True].reset_index()[['index','dark_score']]

dark_images

# seeing some sample images with low information
for score, i in zip(dark_images['dark_score'], dark_images['index']):
  plt.imshow(train_images[i])
  print(score)
  plt.show()

imagelab.visualize(issue_types=["dark"], num_images=20)

dark_img_index = dark_images['index']

"""## Check for duplicate Images
To manually implement this you will have to convert the images into embeddings and then using a similarity measure you can check if the images are similiar or not. If the similarity is too high means they are near duplicates.
"""

duplicate_images = issue_df[issue_df['is_near_duplicates_issue'] == True].reset_index()[['index','near_duplicates_score']]

duplicate_images

# visualizing 5 near duplicate sets
imagelab.visualize(issue_types=["near_duplicates"], num_images=5)

print(f'Total #Duplicate Sets Found : {len(imagelab.info["near_duplicates"]["sets"])}')

duplicate_images_index = []
for i in imagelab.info["near_duplicates"]["sets"]:
  for j,counter in zip(i,range(0,len(i))):
    if counter == 0:
      continue
    else:
      duplicate_images_index.append(j)

"""## Removing Issue Based Images from the Dataset"""

img_index_to_remove = list(set(list(img_index_with_low_information) + list(dark_img_index) + list(duplicate_images_index)))

reduced_train_images = []
reduced_train_labels = []

for counter, im, label in zip(range(len(train_images)), train_images, train_labels):
  if counter in img_index_to_remove:
    continue
  else:
    reduced_train_images.append(im)
    reduced_train_labels.append(label)

"""# **Image Resizing / Transformations**
Here we check if all the images are of same shape and size, else we perform some transformations / reshaping
"""

size_list = [reduced_train_images[i].shape for i in range(len(reduced_train_images))]
print(set(size_list))

"""Hence this shows that all the images in our dataset are of size 28*28 hence we dont need to do any reshaping

# **Normalize Data**
Here we normalize our pixel values in dataset from 0-255 to 0-1
"""

reduced_train_images[0]

def normalize_image_np(image):
    norm_img = (image - np.min(image)) / (np.max(image) - np.min(image))
    return norm_img

normalized_train_images = [normalize_image_np(image) for image in reduced_train_images]

normalized_train_images[0]

normalized_train_images = np.array(normalized_train_images)

"""# **Data Exploration**

## Create Embeddings using Eigen Value Decomposition (PCA)
"""

# flattening the images
X_train = normalized_train_images.reshape(50503, 28 * 28)
Y_train = reduced_train_labels

# fitting PCA
pca = PCA(n_components = None)
X_new = pca.fit_transform(X_train)

# Calculating new no of features such that 85% of the information in the dataset is retained
threshold = 0.85
cumulative_variance = np.cumsum(pca.explained_variance_ratio_)
n_components = np.argmax(cumulative_variance >= threshold) + 1
print(n_components)

"""Hence we can say that we have extracted 195 features out of 28*28 features which retains 95% of the information in the dataset"""

# fitting PCA again to get those 195 features
pca = PCA(n_components = n_components)
X_train = pca.fit_transform(X_train)
pd.DataFrame(X_train)

"""### Visualization"""

# creating 2d features to plot a diagram
pca = PCA(n_components = 2)
X_new_temp = pca.fit_transform(X_train)

dataset = pd.DataFrame(X_new_temp, columns=['Feature 1', 'Feature 2'])
dataset['Label'] = reduced_train_labels

plt.figure(figsize=(12, 8))
colors = plt.cm.tab10(np.linspace(0, 1, 10))  # Use a colormap to get distinct colors for each class

for class_value in range(10):
    subset = dataset[dataset['Label'] == class_value]
    plt.scatter(subset['Feature 1'], subset['Feature 2'], label=f'Class {class_value}', color=colors[class_value])

plt.title('Classification Dataset with 2 Features and 10 Classes')
plt.xlabel('Feature 1')
plt.ylabel('Feature 2')
plt.legend()
plt.grid(True)
plt.show()

"""## Independent Feature Correlation Analysis
Using this we can decide which feature to drop. If two features are highly correlated then we can drop one of them since they are almost similar features
"""

numerical_features = pd.DataFrame(X_train).select_dtypes(include=np.number)

# Calculate the correlation matrix
correlation_matrix = numerical_features.corr()

# Mask the upper triangle for better readability
mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))

# Create the heatmap
plt.figure(figsize=(100, 100))
sns.heatmap(correlation_matrix, mask=mask, annot=False, cmap='coolwarm', fmt=".2f", linewidths=.5)
plt.title('Correlation Matrix of Numerical Features in Boston Housing Data', fontsize=16)
plt.show()

"""## Outlier Handling

#### Predicting outliers using Isolation Forest
"""

from sklearn.ensemble import IsolationForest

clf = IsolationForest(random_state=42)
clf.fit(X_train)
outlier_pred = clf.predict(X_train)

'''
clf = KNN()
clf.fit(X_new)
y_train_pred = clf.labels_  # binary labels (0: inliers, 1: outliers)
# y_train_scores = clf.decision_scores_  # raw outlier scores


# outlier_img_index = []
# for i in range(len(y_train_pred)):
#   if y_train_pred[i] == -1:
#     outlier_img_index.append(i)

# X_outliers_removed = []
# Y_outliers_removed = []

# for counter, im, label in zip(range(len(reduced_train_labels)), X_new, reduced_train_labels):

#   if counter in outlier_img_index:
#     continue

#   else:
#     X_outliers_removed.append(im)
#     Y_outliers_removed.append(label)

# #
# labels = dataset['Label']
# labels[outlier_img_index] = 10
# dataset['Label'] = labels
'''

"""#### 2D visualization after removing outliers"""

dataset['outlier'] = outlier_pred # adding a outlier col in the dataset
dataset['Label'] = dataset['Label'].where(dataset['outlier'] != -1, 10) # creating outlier points as class 10

plt.figure(figsize=(12, 8))
colors = plt.cm.tab10(np.linspace(0, 1, 11))  # Use a colormap to get distinct colors for each class

for class_value in range(11):
    subset = dataset[dataset['Label'] == class_value]
    if class_value == 10:
      plt.scatter(subset['Feature 1'], subset['Feature 2'], label=f'Outliers', color='black')
    else:
      plt.scatter(subset['Feature 1'], subset['Feature 2'], label=f'Class {class_value}', color=colors[class_value])

plt.title('Classification Dataset with 2 Features and 10 Classes')
plt.xlabel('Feature 1')
plt.ylabel('Feature 2')
plt.legend()
plt.grid(True)
plt.show()

"""Note : In 2d plot they might not look at outliers since we have reduced the dimensions but in the original dimensions they are outliers based on isolation forest method

#### Dataset after removal of outliers
"""

train_df = pd.DataFrame(X_train)
train_df['Label'] = Y_train
train_df['outlier'] = outlier_pred

train_df = train_df[train_df['outlier'] != -1]

X_train = np.array(train_df.drop(['Label', 'outlier'], axis=1))
Y_train = np.array(train_df['Label'])

"""## Hypothesis Testing

Hypothesis testing is not possible on this image dataset!!

'Reason :'

Since this is an image dataset which we have converted to a tabular dataset using Eign Value (PCA) Embeddings, we dont know what exactly are the mature feature definitions. This image2embeddings conversion is called automatic feature engineering.


For instance, if we manually create matured features like perimeter = 2*(height + width) we know the definition of matured feature in this case. But in case of automated feature generation we dont know what exact does it mean. (Infact there is a complete research area on this topic : Explainable AI)


Since we dont know the matured feature definition we cannot formulate a null / alternate hypothesis for this. It would not make any sense.
"""

