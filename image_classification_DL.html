<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>e0e731c3c3e14e6084954e9fd101fd72</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<div class="cell markdown" id="Tl5Rk03fQ4GR">
<p><a
href="https://colab.research.google.com/github/khetansarvesh/MSML_602/blob/main/image_classification_DL.ipynb"><img
src="https://colab.research.google.com/assets/colab-badge.svg"
alt="Open In Colab" /></a></p>
</div>
<section
id="---image-classification-using-feed-forwared-neural-networks--convolution-neural-networks--vision-transformers---"
class="cell markdown" id="k4a2083QJM0e">
<h1><h1> <b> <center> Image Classification Using Feed Forwared Neural
Networks / Convolution Neural Networks / Vision Transformers </center>
</b> </h1></h1>
<p>Collaborators:</p>
<ul>
<li>Sarvesh Khetan</li>
<li>Siri Reddy</li>
<li>Umesh Adari</li>
</ul>
</section>
<section id="---introduction---" class="cell markdown"
id="aNYE_AwTJNin">
<h1><h1> <b> <center> Introduction </center> </b> </h1></h1>
<div> <center>
In the ever changing world of online shopping, product categorization accuracy is becoming more and more crucial. Customers will be more satisfied and have greater conversion rates if they can quickly search for and locate the products they want thanks to an automatic tagging system that works well. But one of the biggest problems in creating such systems is the noisy data present, where objects maybe incorrectly identified for a number of reasons, including mislabeling or unclear labeling made during data collection or because of a bad model. Hence our aim is to build such a model which is robust to noisy data. Researcher have found multiple ways to do so using Deep Learning. We want to see how these different Deep Learning models perform on this type of dataset. Answering these questions are important because it will help us understand how these models tend to reason and the mathematics behind these models. Having a good understanding will lead to further research in this area to solve issues faced by the already existing model architectures!!
</center> </div>
</section>
<section id="---installing-relevant-libraries---" class="cell markdown"
id="0Dam9SpHfErv">
<h1><h1> <b> <center> Installing Relevant Libraries </center> </b>
</h1></h1>
</section>
<div class="cell code" id="sggk81lTQ4GT"
data-vscode="{&quot;languageId&quot;:&quot;plaintext&quot;}">
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># !pip install &quot;cleanvision[huggingface]&quot;</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="co"># !pip install pyod</span></span></code></pre></div>
</div>
<section id="---relevant-imports---" class="cell markdown"
id="TZbFUnIZfBdO">
<h1><h1> <b> <center> Relevant Imports </center> </b> </h1></h1>
</section>
<div class="cell code" id="a67_U5OAQ4GT"
data-vscode="{&quot;languageId&quot;:&quot;plaintext&quot;}">
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import PyTorch</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch <span class="im">import</span> nn</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="co"># import pandas as pd</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datasets <span class="im">import</span> load_dataset, concatenate_datasets</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> cleanvision <span class="im">import</span> Imagelab</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> requests</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> cv2</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> imagehash</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Import torchvision</span></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision <span class="im">import</span> datasets</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision.transforms <span class="im">import</span> ToTensor</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision.transforms <span class="im">as</span> transforms</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader, TensorDataset</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Import matplotlib for visualization</span></span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tqdm.auto <span class="im">import</span> tqdm</span></code></pre></div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="gxEVpWg0Q4GU" data-outputId="bcd66a9d-7e04-4b08-8eae-eb33b727d32d"
data-vscode="{&quot;languageId&quot;:&quot;plaintext&quot;}">
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> <span class="st">&quot;cuda&quot;</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">&quot;cpu&quot;</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(device)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>cuda
</code></pre>
</div>
</div>
<section id="---data-curation---" class="cell markdown"
id="RaCabIi4Q4GU">
<h1><h1> <b> <center> Data curation </center> </b> </h1></h1>
<p>Earlier we planned to use <a
href="https://paperswithcode.com/dataset/clothing1m">Clothing1M
dataset</a> but the authors of this paper have not reverted back with
the dataset drive link and hence we pivoted to using the fashionMNIST
dataset. Here are some key things to know about <a
href="https://github.com/zalandoresearch/fashion-mnist">fashion MNIST
dataset</a> :</p>
<ul>
<li><p>It consists of 70,000 grayscale images of fashion products from
10 categories.</p></li>
<li><p>The dataset is split into 60,000 training images and 10,000 test
images.</p></li>
<li><p>Each image is 28x28 pixels in size.</p></li>
<li><p>The images are in grayscale, with pixel values ranging from 0 to
255.</p></li>
<li><p>There are 10 classes of fashion items, including T-shirts,
trousers, dresses, and more.</p></li>
<li><p>It was created by Zalando Research as a more challenging
alternative to the original MNIST dataset.</p></li>
<li><p>Fashion MNIST shares the same image size, data format, and
structure of training and testing splits with the original MNIST
dataset.</p></li>
</ul>
</section>
<section id="downloading-dataset" class="cell markdown"
id="eWU9yxRQYhCF">
<h3>Downloading Dataset</h3>
</section>
<div class="cell code" id="NDh11cdaQ4GU"
data-vscode="{&quot;languageId&quot;:&quot;plaintext&quot;}">
<div class="sourceCode" id="cb5"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>dataset_dict <span class="op">=</span> load_dataset(<span class="st">&quot;zalando-datasets/fashion_mnist&quot;</span>)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="co"># train dataset</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>train_data <span class="op">=</span> dataset_dict[<span class="st">&#39;train&#39;</span>]</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>train_images <span class="op">=</span> np.array(train_data[<span class="st">&#39;image&#39;</span>])</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>train_labels <span class="op">=</span> np.array(train_data[<span class="st">&#39;label&#39;</span>])</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="co"># test dataset</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>test_data <span class="op">=</span> dataset_dict[<span class="st">&#39;test&#39;</span>]</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>test_images <span class="op">=</span> np.array(test_data[<span class="st">&#39;image&#39;</span>])</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>test_labels <span class="op">=</span> np.array(test_data[<span class="st">&#39;label&#39;</span>])</span></code></pre></div>
</div>
<section id="visualizing-dataset" class="cell markdown"
id="kaPQt4y2Ye5G">
<h3>Visualizing Dataset</h3>
</section>
<div class="cell code" id="T6exfAo4WhgG">
<div class="sourceCode" id="cb6"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>label_dic <span class="op">=</span> {</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>    <span class="dv">0</span> : <span class="st">&#39;T-shirt/top&#39;</span>,</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>    <span class="dv">1</span> : <span class="st">&#39;Trouser&#39;</span>,</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>    <span class="dv">2</span> : <span class="st">&#39;Pullover&#39;</span>,</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>    <span class="dv">3</span> : <span class="st">&#39;Dress&#39;</span>,</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>    <span class="dv">4</span> : <span class="st">&#39;Coat&#39;</span>,</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>    <span class="dv">5</span> : <span class="st">&#39;Sandal&#39;</span>,</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>    <span class="dv">6</span> : <span class="st">&#39;shirt&#39;</span>,</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>    <span class="dv">7</span> : <span class="st">&#39;Sneaker&#39;</span>,</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>    <span class="dv">8</span> : <span class="st">&#39;Bag&#39;</span>,</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>    <span class="dv">9</span> : <span class="st">&#39;Ankle boot&#39;</span></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="SmOcJqIAQ4GU" data-outputId="9e9a8fda-4f5a-45b7-b5bb-07824ce8db4e"
data-vscode="{&quot;languageId&quot;:&quot;plaintext&quot;}">
<div class="sourceCode" id="cb7"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot more images</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">42</span>)</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> plt.figure(figsize<span class="op">=</span>(<span class="dv">9</span>, <span class="dv">9</span>))</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">4</span> <span class="op">*</span> <span class="dv">4</span> <span class="op">+</span> <span class="dv">1</span>):</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>    random_idx <span class="op">=</span> torch.randint(<span class="dv">0</span>, <span class="bu">len</span>(train_data), size<span class="op">=</span>[<span class="dv">1</span>]).item()</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> train_images[random_idx]</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>    label <span class="op">=</span> train_labels[random_idx]</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>    fig.add_subplot(<span class="dv">4</span>, <span class="dv">4</span>, i)</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>    plt.imshow(img.squeeze(), cmap<span class="op">=</span><span class="st">&quot;gray&quot;</span>)</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="ss">f&#39;</span><span class="sc">{</span>label_dic[label]<span class="sc">}</span><span class="ss">-</span><span class="sc">{</span>label<span class="sc">}</span><span class="ss">&#39;</span>)</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>    plt.axis(<span class="va">False</span>)<span class="op">;</span></span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_889211e4574a44c3907c85a1cc095ae7/351349a98a7e061bd8944e630c40f31ccef7a2cc.png" /></p>
</div>
</div>
<section id="---data-cleaning---" class="cell markdown"
id="kD_nIWDLMavl">
<h1><h1> <b> <center> Data Cleaning </center> </b> </h1></h1>
<p>Before performing any analysis on our dataset we need to make sure
that our data is good else the model built on this data would not be a
good model. Hence here in this section we will try to remove all the
irregularities present in the dataset. Some of the irregularities can be
duplicate images / images with low information / blurry images / dark
images / light images / ...</p>
</section>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;referenced_widgets&quot;:[&quot;407ba51be4c44c3fa0b8d45f8366d766&quot;,&quot;e4d64a3393ed4da1879fe46e1c1a999b&quot;,&quot;7faa827989584df3aedebb6e25cb1f43&quot;,&quot;3fba60a7a20d4615a595343b5e7a5847&quot;,&quot;eefa75583459485fb2cdb34c9be9c60a&quot;,&quot;8c619920ccf741dc9fc06baef1c698bd&quot;,&quot;1be832a80a8a4145ab507e0d665d188f&quot;,&quot;6227b931de5445f3a075d8545dcd7c6c&quot;,&quot;2603ae7d2faf49e787c215b6ed014f70&quot;,&quot;1501eba27aa646eb8fd9bac3bb511f9c&quot;,&quot;5efa1b286b5c4877ab9274b302d8e0b4&quot;,&quot;8f859670affa445cbbb750a02b6af7c1&quot;,&quot;4783e3f1c9fa42e0a53cb73a589a7507&quot;,&quot;6eb0801aa15c45738775a1be7d2e51fd&quot;,&quot;a9b019b6a26a4052a2557848bd2643d0&quot;,&quot;81bde00471364f6c9a8fe70c71e9983a&quot;,&quot;af8a48ff4d5146f2ad70c62e75766032&quot;,&quot;327858c9902f47d0823f48358dc795d6&quot;,&quot;7b8e579101b7485a87dbb3d2fe340e8b&quot;,&quot;9a02e59933c54d19b698435b08010ae1&quot;,&quot;2b8f5beed6e24a3fbd9c725fc4d094e0&quot;,&quot;504db23ef0ce4c1d9748efcace9e45a3&quot;]}"
id="C4qFw-ayj4gL" data-outputId="8565f575-55ea-4169-846f-1a56e3a5573c">
<div class="sourceCode" id="cb8"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>imagelab <span class="op">=</span> Imagelab(hf_dataset<span class="op">=</span>train_data, image_key<span class="op">=</span><span class="st">&quot;image&quot;</span>)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>imagelab.find_issues()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Checking for dark, light, odd_aspect_ratio, low_information, exact_duplicates, near_duplicates, blurry, grayscale, odd_size images ...
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb10"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;407ba51be4c44c3fa0b8d45f8366d766&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb11"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;8f859670affa445cbbb750a02b6af7c1&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stdout">
<pre><code>Issue checks completed. 70003 issues found in the dataset. To see a detailed report of issues found, use imagelab.report().
</code></pre>
</div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="3JmWo8rKkFka" data-outputId="84a37b87-fb83-4c25-9df8-1f35a2d776a0">
<div class="sourceCode" id="cb13"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>imagelab.issue_summary</span></code></pre></div>
<div class="output execute_result" data-execution_count="63">

  <div id="df-58ec3bb6-7bba-497f-b732-ffd686142ae1" class="colab-df-container">
    <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>issue_type</th>
      <th>num_images</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>grayscale</td>
      <td>60000</td>
    </tr>
    <tr>
      <th>1</th>
      <td>low_information</td>
      <td>9266</td>
    </tr>
    <tr>
      <th>2</th>
      <td>near_duplicates</td>
      <td>721</td>
    </tr>
    <tr>
      <th>3</th>
      <td>dark</td>
      <td>16</td>
    </tr>
    <tr>
      <th>4</th>
      <td>light</td>
      <td>0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>odd_aspect_ratio</td>
      <td>0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>blurry</td>
      <td>0</td>
    </tr>
    <tr>
      <th>7</th>
      <td>odd_size</td>
      <td>0</td>
    </tr>
    <tr>
      <th>8</th>
      <td>exact_duplicates</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-58ec3bb6-7bba-497f-b732-ffd686142ae1')"
            title="Convert this dataframe to an interactive table."
            style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"/>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-58ec3bb6-7bba-497f-b732-ffd686142ae1 button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-58ec3bb6-7bba-497f-b732-ffd686142ae1');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


<div id="df-c63c58bc-f8b3-4978-9877-62b415db64de">
  <button class="colab-df-quickchart" onclick="quickchart('df-c63c58bc-f8b3-4978-9877-62b415db64de')"
            title="Suggest charts"
            style="display:none;">

<svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
     width="24px">
    <g>
        <path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z"/>
    </g>
</svg>
  </button>

<style>
  .colab-df-quickchart {
      --bg-color: #E8F0FE;
      --fill-color: #1967D2;
      --hover-bg-color: #E2EBFA;
      --hover-fill-color: #174EA6;
      --disabled-fill-color: #AAA;
      --disabled-bg-color: #DDD;
  }

  [theme=dark] .colab-df-quickchart {
      --bg-color: #3B4455;
      --fill-color: #D2E3FC;
      --hover-bg-color: #434B5C;
      --hover-fill-color: #FFFFFF;
      --disabled-bg-color: #3B4455;
      --disabled-fill-color: #666;
  }

  .colab-df-quickchart {
    background-color: var(--bg-color);
    border: none;
    border-radius: 50%;
    cursor: pointer;
    display: none;
    fill: var(--fill-color);
    height: 32px;
    padding: 0;
    width: 32px;
  }

  .colab-df-quickchart:hover {
    background-color: var(--hover-bg-color);
    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);
    fill: var(--button-hover-fill-color);
  }

  .colab-df-quickchart-complete:disabled,
  .colab-df-quickchart-complete:disabled:hover {
    background-color: var(--disabled-bg-color);
    fill: var(--disabled-fill-color);
    box-shadow: none;
  }

  .colab-df-spinner {
    border: 2px solid var(--fill-color);
    border-color: transparent;
    border-bottom-color: var(--fill-color);
    animation:
      spin 1s steps(1) infinite;
  }

  @keyframes spin {
    0% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
      border-left-color: var(--fill-color);
    }
    20% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    30% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
      border-right-color: var(--fill-color);
    }
    40% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    60% {
      border-color: transparent;
      border-right-color: var(--fill-color);
    }
    80% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-bottom-color: var(--fill-color);
    }
    90% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
    }
  }
</style>

  <script>
    async function quickchart(key) {
      const quickchartButtonEl =
        document.querySelector('#' + key + ' button');
      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.
      quickchartButtonEl.classList.add('colab-df-spinner');
      try {
        const charts = await google.colab.kernel.invokeFunction(
            'suggestCharts', [key], {});
      } catch (error) {
        console.error('Error during call to suggestCharts:', error);
      }
      quickchartButtonEl.classList.remove('colab-df-spinner');
      quickchartButtonEl.classList.add('colab-df-quickchart-complete');
    }
    (() => {
      let quickchartButtonEl =
        document.querySelector('#df-c63c58bc-f8b3-4978-9877-62b415db64de button');
      quickchartButtonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';
    })();
  </script>
</div>

    </div>
  </div>

</div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="XDvSDEnEj_XM" data-outputId="288bbbd2-70d7-4d61-8077-7b9b67f75c91">
<div class="sourceCode" id="cb14"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>issue_df <span class="op">=</span> imagelab.issues</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>issue_df</span></code></pre></div>
<div class="output execute_result" data-execution_count="64">

  <div id="df-cda8f672-4342-42d4-b42f-263b39dc6974" class="colab-df-container">
    <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>odd_size_score</th>
      <th>is_odd_size_issue</th>
      <th>odd_aspect_ratio_score</th>
      <th>is_odd_aspect_ratio_issue</th>
      <th>low_information_score</th>
      <th>is_low_information_issue</th>
      <th>light_score</th>
      <th>is_light_issue</th>
      <th>grayscale_score</th>
      <th>is_grayscale_issue</th>
      <th>dark_score</th>
      <th>is_dark_issue</th>
      <th>blurry_score</th>
      <th>is_blurry_issue</th>
      <th>exact_duplicates_score</th>
      <th>is_exact_duplicates_issue</th>
      <th>near_duplicates_score</th>
      <th>is_near_duplicates_issue</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.0</td>
      <td>False</td>
      <td>1.0</td>
      <td>False</td>
      <td>0.471182</td>
      <td>False</td>
      <td>1.0</td>
      <td>False</td>
      <td>0</td>
      <td>True</td>
      <td>0.964706</td>
      <td>False</td>
      <td>0.782126</td>
      <td>False</td>
      <td>1.0</td>
      <td>False</td>
      <td>1.0</td>
      <td>False</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1.0</td>
      <td>False</td>
      <td>1.0</td>
      <td>False</td>
      <td>0.488036</td>
      <td>False</td>
      <td>1.0</td>
      <td>False</td>
      <td>0</td>
      <td>True</td>
      <td>0.992824</td>
      <td>False</td>
      <td>0.609102</td>
      <td>False</td>
      <td>1.0</td>
      <td>False</td>
      <td>1.0</td>
      <td>False</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.0</td>
      <td>False</td>
      <td>1.0</td>
      <td>False</td>
      <td>0.307095</td>
      <td>False</td>
      <td>1.0</td>
      <td>False</td>
      <td>0</td>
      <td>True</td>
      <td>0.835373</td>
      <td>False</td>
      <td>0.759629</td>
      <td>False</td>
      <td>1.0</td>
      <td>False</td>
      <td>1.0</td>
      <td>False</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1.0</td>
      <td>False</td>
      <td>1.0</td>
      <td>False</td>
      <td>0.412742</td>
      <td>False</td>
      <td>1.0</td>
      <td>False</td>
      <td>0</td>
      <td>True</td>
      <td>0.762118</td>
      <td>False</td>
      <td>0.793485</td>
      <td>False</td>
      <td>1.0</td>
      <td>False</td>
      <td>1.0</td>
      <td>False</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1.0</td>
      <td>False</td>
      <td>1.0</td>
      <td>False</td>
      <td>0.326907</td>
      <td>False</td>
      <td>1.0</td>
      <td>False</td>
      <td>0</td>
      <td>True</td>
      <td>1.000000</td>
      <td>False</td>
      <td>0.830525</td>
      <td>False</td>
      <td>1.0</td>
      <td>False</td>
      <td>1.0</td>
      <td>False</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>59995</th>
      <td>1.0</td>
      <td>False</td>
      <td>1.0</td>
      <td>False</td>
      <td>0.273430</td>
      <td>True</td>
      <td>1.0</td>
      <td>False</td>
      <td>0</td>
      <td>True</td>
      <td>0.868078</td>
      <td>False</td>
      <td>0.830474</td>
      <td>False</td>
      <td>1.0</td>
      <td>False</td>
      <td>1.0</td>
      <td>False</td>
    </tr>
    <tr>
      <th>59996</th>
      <td>1.0</td>
      <td>False</td>
      <td>1.0</td>
      <td>False</td>
      <td>0.277721</td>
      <td>True</td>
      <td>1.0</td>
      <td>False</td>
      <td>0</td>
      <td>True</td>
      <td>0.996078</td>
      <td>False</td>
      <td>0.867324</td>
      <td>False</td>
      <td>1.0</td>
      <td>False</td>
      <td>1.0</td>
      <td>False</td>
    </tr>
    <tr>
      <th>59997</th>
      <td>1.0</td>
      <td>False</td>
      <td>1.0</td>
      <td>False</td>
      <td>0.348192</td>
      <td>False</td>
      <td>1.0</td>
      <td>False</td>
      <td>0</td>
      <td>True</td>
      <td>1.000000</td>
      <td>False</td>
      <td>0.852952</td>
      <td>False</td>
      <td>1.0</td>
      <td>False</td>
      <td>1.0</td>
      <td>False</td>
    </tr>
    <tr>
      <th>59998</th>
      <td>1.0</td>
      <td>False</td>
      <td>1.0</td>
      <td>False</td>
      <td>0.436144</td>
      <td>False</td>
      <td>1.0</td>
      <td>False</td>
      <td>0</td>
      <td>True</td>
      <td>0.620275</td>
      <td>False</td>
      <td>0.507929</td>
      <td>False</td>
      <td>1.0</td>
      <td>False</td>
      <td>1.0</td>
      <td>False</td>
    </tr>
    <tr>
      <th>59999</th>
      <td>1.0</td>
      <td>False</td>
      <td>1.0</td>
      <td>False</td>
      <td>0.242515</td>
      <td>True</td>
      <td>1.0</td>
      <td>False</td>
      <td>0</td>
      <td>True</td>
      <td>0.784980</td>
      <td>False</td>
      <td>0.820678</td>
      <td>False</td>
      <td>1.0</td>
      <td>False</td>
      <td>1.0</td>
      <td>False</td>
    </tr>
  </tbody>
</table>
<p>60000 rows Ã— 18 columns</p>
</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-cda8f672-4342-42d4-b42f-263b39dc6974')"
            title="Convert this dataframe to an interactive table."
            style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"/>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-cda8f672-4342-42d4-b42f-263b39dc6974 button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-cda8f672-4342-42d4-b42f-263b39dc6974');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


<div id="df-da6e5387-b050-4ddb-bed8-09316a2d9f1c">
  <button class="colab-df-quickchart" onclick="quickchart('df-da6e5387-b050-4ddb-bed8-09316a2d9f1c')"
            title="Suggest charts"
            style="display:none;">

<svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
     width="24px">
    <g>
        <path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z"/>
    </g>
</svg>
  </button>

<style>
  .colab-df-quickchart {
      --bg-color: #E8F0FE;
      --fill-color: #1967D2;
      --hover-bg-color: #E2EBFA;
      --hover-fill-color: #174EA6;
      --disabled-fill-color: #AAA;
      --disabled-bg-color: #DDD;
  }

  [theme=dark] .colab-df-quickchart {
      --bg-color: #3B4455;
      --fill-color: #D2E3FC;
      --hover-bg-color: #434B5C;
      --hover-fill-color: #FFFFFF;
      --disabled-bg-color: #3B4455;
      --disabled-fill-color: #666;
  }

  .colab-df-quickchart {
    background-color: var(--bg-color);
    border: none;
    border-radius: 50%;
    cursor: pointer;
    display: none;
    fill: var(--fill-color);
    height: 32px;
    padding: 0;
    width: 32px;
  }

  .colab-df-quickchart:hover {
    background-color: var(--hover-bg-color);
    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);
    fill: var(--button-hover-fill-color);
  }

  .colab-df-quickchart-complete:disabled,
  .colab-df-quickchart-complete:disabled:hover {
    background-color: var(--disabled-bg-color);
    fill: var(--disabled-fill-color);
    box-shadow: none;
  }

  .colab-df-spinner {
    border: 2px solid var(--fill-color);
    border-color: transparent;
    border-bottom-color: var(--fill-color);
    animation:
      spin 1s steps(1) infinite;
  }

  @keyframes spin {
    0% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
      border-left-color: var(--fill-color);
    }
    20% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    30% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
      border-right-color: var(--fill-color);
    }
    40% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    60% {
      border-color: transparent;
      border-right-color: var(--fill-color);
    }
    80% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-bottom-color: var(--fill-color);
    }
    90% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
    }
  }
</style>

  <script>
    async function quickchart(key) {
      const quickchartButtonEl =
        document.querySelector('#' + key + ' button');
      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.
      quickchartButtonEl.classList.add('colab-df-spinner');
      try {
        const charts = await google.colab.kernel.invokeFunction(
            'suggestCharts', [key], {});
      } catch (error) {
        console.error('Error during call to suggestCharts:', error);
      }
      quickchartButtonEl.classList.remove('colab-df-spinner');
      quickchartButtonEl.classList.add('colab-df-quickchart-complete');
    }
    (() => {
      let quickchartButtonEl =
        document.querySelector('#df-da6e5387-b050-4ddb-bed8-09316a2d9f1c button');
      quickchartButtonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';
    })();
  </script>
</div>

  <div id="id_2e5dabc2-49de-4c45-988b-892f37eb49ee">
    <style>
      .colab-df-generate {
        background-color: #E8F0FE;
        border: none;
        border-radius: 50%;
        cursor: pointer;
        display: none;
        fill: #1967D2;
        height: 32px;
        padding: 0 0 0 0;
        width: 32px;
      }

      .colab-df-generate:hover {
        background-color: #E2EBFA;
        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
        fill: #174EA6;
      }

      [theme=dark] .colab-df-generate {
        background-color: #3B4455;
        fill: #D2E3FC;
      }

      [theme=dark] .colab-df-generate:hover {
        background-color: #434B5C;
        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
        fill: #FFFFFF;
      }
    </style>
    <button class="colab-df-generate" onclick="generateWithVariable('issue_df')"
            title="Generate code using this dataframe."
            style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z"/>
  </svg>
    </button>
    <script>
      (() => {
      const buttonEl =
        document.querySelector('#id_2e5dabc2-49de-4c45-988b-892f37eb49ee button.colab-df-generate');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      buttonEl.onclick = () => {
        google.colab.notebook.generateWithVariable('issue_df');
      }
      })();
    </script>
  </div>

    </div>
  </div>

</div>
</div>
<section id="check-for-images-with-low-information-in-dataset"
class="cell markdown" id="eZyXnWI9kLhm">
<h2>Check for Images with Low Information in dataset</h2>
<p>There are many ways to check if the image contains low information or
not eg using entropy value or using variance across different axes of
the image.</p>
</section>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="RQKwcIMqkQSL" data-outputId="26e67116-88bd-4308-904b-6b94104946b8">
<div class="sourceCode" id="cb15"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>images_with_low_information <span class="op">=</span> issue_df[issue_df[<span class="st">&#39;is_low_information_issue&#39;</span>] <span class="op">==</span> <span class="va">True</span>].reset_index()[[<span class="st">&#39;index&#39;</span>,<span class="st">&#39;low_information_score&#39;</span>]]</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>images_with_low_information</span></code></pre></div>
<div class="output execute_result" data-execution_count="65">

  <div id="df-0f985035-aad7-4651-b682-f06526796671" class="colab-df-container">
    <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>index</th>
      <th>low_information_score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>8</td>
      <td>0.292135</td>
    </tr>
    <tr>
      <th>1</th>
      <td>13</td>
      <td>0.296907</td>
    </tr>
    <tr>
      <th>2</th>
      <td>14</td>
      <td>0.244999</td>
    </tr>
    <tr>
      <th>3</th>
      <td>30</td>
      <td>0.169186</td>
    </tr>
    <tr>
      <th>4</th>
      <td>38</td>
      <td>0.294015</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>9261</th>
      <td>59951</td>
      <td>0.268701</td>
    </tr>
    <tr>
      <th>9262</th>
      <td>59991</td>
      <td>0.267101</td>
    </tr>
    <tr>
      <th>9263</th>
      <td>59995</td>
      <td>0.273430</td>
    </tr>
    <tr>
      <th>9264</th>
      <td>59996</td>
      <td>0.277721</td>
    </tr>
    <tr>
      <th>9265</th>
      <td>59999</td>
      <td>0.242515</td>
    </tr>
  </tbody>
</table>
<p>9266 rows Ã— 2 columns</p>
</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-0f985035-aad7-4651-b682-f06526796671')"
            title="Convert this dataframe to an interactive table."
            style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"/>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-0f985035-aad7-4651-b682-f06526796671 button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-0f985035-aad7-4651-b682-f06526796671');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


<div id="df-a586fd1a-b536-4a65-ad8b-a06ea5f390b7">
  <button class="colab-df-quickchart" onclick="quickchart('df-a586fd1a-b536-4a65-ad8b-a06ea5f390b7')"
            title="Suggest charts"
            style="display:none;">

<svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
     width="24px">
    <g>
        <path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z"/>
    </g>
</svg>
  </button>

<style>
  .colab-df-quickchart {
      --bg-color: #E8F0FE;
      --fill-color: #1967D2;
      --hover-bg-color: #E2EBFA;
      --hover-fill-color: #174EA6;
      --disabled-fill-color: #AAA;
      --disabled-bg-color: #DDD;
  }

  [theme=dark] .colab-df-quickchart {
      --bg-color: #3B4455;
      --fill-color: #D2E3FC;
      --hover-bg-color: #434B5C;
      --hover-fill-color: #FFFFFF;
      --disabled-bg-color: #3B4455;
      --disabled-fill-color: #666;
  }

  .colab-df-quickchart {
    background-color: var(--bg-color);
    border: none;
    border-radius: 50%;
    cursor: pointer;
    display: none;
    fill: var(--fill-color);
    height: 32px;
    padding: 0;
    width: 32px;
  }

  .colab-df-quickchart:hover {
    background-color: var(--hover-bg-color);
    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);
    fill: var(--button-hover-fill-color);
  }

  .colab-df-quickchart-complete:disabled,
  .colab-df-quickchart-complete:disabled:hover {
    background-color: var(--disabled-bg-color);
    fill: var(--disabled-fill-color);
    box-shadow: none;
  }

  .colab-df-spinner {
    border: 2px solid var(--fill-color);
    border-color: transparent;
    border-bottom-color: var(--fill-color);
    animation:
      spin 1s steps(1) infinite;
  }

  @keyframes spin {
    0% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
      border-left-color: var(--fill-color);
    }
    20% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    30% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
      border-right-color: var(--fill-color);
    }
    40% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    60% {
      border-color: transparent;
      border-right-color: var(--fill-color);
    }
    80% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-bottom-color: var(--fill-color);
    }
    90% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
    }
  }
</style>

  <script>
    async function quickchart(key) {
      const quickchartButtonEl =
        document.querySelector('#' + key + ' button');
      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.
      quickchartButtonEl.classList.add('colab-df-spinner');
      try {
        const charts = await google.colab.kernel.invokeFunction(
            'suggestCharts', [key], {});
      } catch (error) {
        console.error('Error during call to suggestCharts:', error);
      }
      quickchartButtonEl.classList.remove('colab-df-spinner');
      quickchartButtonEl.classList.add('colab-df-quickchart-complete');
    }
    (() => {
      let quickchartButtonEl =
        document.querySelector('#df-a586fd1a-b536-4a65-ad8b-a06ea5f390b7 button');
      quickchartButtonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';
    })();
  </script>
</div>

  <div id="id_14d3cb09-ad2e-4329-a3f9-636fb6c94a8a">
    <style>
      .colab-df-generate {
        background-color: #E8F0FE;
        border: none;
        border-radius: 50%;
        cursor: pointer;
        display: none;
        fill: #1967D2;
        height: 32px;
        padding: 0 0 0 0;
        width: 32px;
      }

      .colab-df-generate:hover {
        background-color: #E2EBFA;
        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
        fill: #174EA6;
      }

      [theme=dark] .colab-df-generate {
        background-color: #3B4455;
        fill: #D2E3FC;
      }

      [theme=dark] .colab-df-generate:hover {
        background-color: #434B5C;
        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
        fill: #FFFFFF;
      }
    </style>
    <button class="colab-df-generate" onclick="generateWithVariable('images_with_low_information')"
            title="Generate code using this dataframe."
            style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z"/>
  </svg>
    </button>
    <script>
      (() => {
      const buttonEl =
        document.querySelector('#id_14d3cb09-ad2e-4329-a3f9-636fb6c94a8a button.colab-df-generate');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      buttonEl.onclick = () => {
        google.colab.notebook.generateWithVariable('images_with_low_information');
      }
      })();
    </script>
  </div>

    </div>
  </div>

</div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="_HENETMQkZPF" data-outputId="2ba577ca-46ea-4a4e-8fa0-6714a2cc7c6b">
<div class="sourceCode" id="cb16"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>imagelab.visualize(issue_types<span class="op">=</span>[<span class="st">&quot;low_information&quot;</span>], num_images<span class="op">=</span><span class="dv">20</span>)</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_889211e4574a44c3907c85a1cc095ae7/e0541dcadd0bc48bfb76355e528d97c5ee8b03f6.png" /></p>
</div>
</div>
<div class="cell code" id="clE4KcLKkcvO">
<div class="sourceCode" id="cb17"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>img_index_with_low_information <span class="op">=</span> images_with_low_information[<span class="st">&#39;index&#39;</span>]</span></code></pre></div>
</div>
<section id="check-for-blurry-images-in-dataset" class="cell markdown"
id="amPzAzMikkYx">
<h2>Check for Blurry Images in dataset</h2>
<p>There are many ways to check blurriness in an image like laplacian
and fourier transform.</p>
<p>Imagelab library suggests that are are no blurry images in our
dataset, let's check that manually too by implementing our own version
to check for blurry images.</p>
</section>
<div class="cell code" id="BFeKYIt6kogo">
<div class="sourceCode" id="cb18"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>is_blurry_image <span class="op">=</span> [cv2.Laplacian(image, cv2.CV_64F).var()<span class="op">&lt;</span><span class="dv">1000</span> <span class="cf">for</span> image <span class="kw">in</span> train_images]</span></code></pre></div>
</div>
<div class="cell code" id="lb99XDSPkoZA">
<div class="sourceCode" id="cb19"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> is_blurry_image:</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> i <span class="op">==</span> <span class="va">True</span>:</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(i)</span></code></pre></div>
</div>
<div class="cell markdown" id="_VVIhRBmkuQn">
<p>Hence this shows that there are no blurry images in our dataset</p>
</div>
<section id="check-for-light--dark-images-in-dataset"
class="cell markdown" id="BiHFgyuHkxC2">
<h2>Check for Light / Dark Images in dataset</h2>
<p>Here we first identify if there are too dark or too light images in
our dataset</p>
</section>
<div class="cell code" id="0uqbCam0k4HB">
<div class="sourceCode" id="cb20"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>dark_images <span class="op">=</span> issue_df[issue_df[<span class="st">&#39;is_dark_issue&#39;</span>] <span class="op">==</span> <span class="va">True</span>].reset_index()[[<span class="st">&#39;index&#39;</span>,<span class="st">&#39;dark_score&#39;</span>]]</span></code></pre></div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="169Pek4Rk8YF" data-outputId="120b587c-6a9f-4757-f2f1-06b36f225a1c">
<div class="sourceCode" id="cb21"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>imagelab.visualize(issue_types<span class="op">=</span>[<span class="st">&quot;dark&quot;</span>], num_images<span class="op">=</span><span class="dv">20</span>)</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_889211e4574a44c3907c85a1cc095ae7/272eade8dd3a86e5a9722a732b3ecbb61c51df78.png" /></p>
</div>
</div>
<div class="cell code" id="M32k_mogk9A5">
<div class="sourceCode" id="cb22"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>dark_img_index <span class="op">=</span> dark_images[<span class="st">&#39;index&#39;</span>]</span></code></pre></div>
</div>
<section id="check-for-duplicate-images" class="cell markdown"
id="IWBt7rwvlBOH">
<h2>Check for duplicate Images</h2>
<p>To manually implement this you will have to convert the images into
embeddings and then using a similarity measure you can check if the
images are similiar or not. If the similarity is too high means they are
near duplicates.</p>
</section>
<div class="cell code" id="JkTlZ_V4loiI">
<div class="sourceCode" id="cb23"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>duplicate_images <span class="op">=</span> issue_df[issue_df[<span class="st">&#39;is_near_duplicates_issue&#39;</span>] <span class="op">==</span> <span class="va">True</span>].reset_index()[[<span class="st">&#39;index&#39;</span>,<span class="st">&#39;near_duplicates_score&#39;</span>]]</span></code></pre></div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="ye52m-3mlpag" data-outputId="654b2554-d57a-4fe2-becd-af993bd8f4c7">
<div class="sourceCode" id="cb24"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># visualizing 5 near duplicate sets</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>imagelab.visualize(issue_types<span class="op">=</span>[<span class="st">&quot;near_duplicates&quot;</span>], num_images<span class="op">=</span><span class="dv">5</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Set: 0
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_889211e4574a44c3907c85a1cc095ae7/d5fa5904fa1ba1e4ddad762dcc52f59404a88ca1.png" /></p>
</div>
<div class="output stream stdout">
<pre><code>Set: 1
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_889211e4574a44c3907c85a1cc095ae7/2d4cedd333bae37e29871bfa7527563eb2753174.png" /></p>
</div>
<div class="output stream stdout">
<pre><code>Set: 2
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_889211e4574a44c3907c85a1cc095ae7/12d0af33c90c040db34f99c4dae5d199ecbbd520.png" /></p>
</div>
<div class="output stream stdout">
<pre><code>Set: 3
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_889211e4574a44c3907c85a1cc095ae7/f67b76294f3bd5249a5d8ee63af35c8bc90f1c3b.png" /></p>
</div>
<div class="output stream stdout">
<pre><code>Set: 4
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_889211e4574a44c3907c85a1cc095ae7/71213067898c6f7cf56dc72e1458eaa50647530c.png" /></p>
</div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="-H7MLD7ZluBq" data-outputId="d53cd21a-ebae-4307-b556-6674f1d59524">
<div class="sourceCode" id="cb30"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;Total #Duplicate Sets Found : </span><span class="sc">{</span><span class="bu">len</span>(imagelab.info[<span class="st">&quot;near_duplicates&quot;</span>][<span class="st">&quot;sets&quot;</span>])<span class="sc">}</span><span class="ss">&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Total #Duplicate Sets Found : 314
</code></pre>
</div>
</div>
<div class="cell code" id="-2xr4U9ZlvQ3">
<div class="sourceCode" id="cb32"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>duplicate_images_index <span class="op">=</span> []</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> imagelab.info[<span class="st">&quot;near_duplicates&quot;</span>][<span class="st">&quot;sets&quot;</span>]:</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> j,counter <span class="kw">in</span> <span class="bu">zip</span>(i,<span class="bu">range</span>(<span class="dv">0</span>,<span class="bu">len</span>(i))):</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> counter <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>      <span class="cf">continue</span></span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a>      duplicate_images_index.append(j)</span></code></pre></div>
</div>
<section id="removing-issue-based-images-from-the-dataset"
class="cell markdown" id="MxDh_mVzly-f">
<h2>Removing Issue Based Images from the Dataset</h2>
</section>
<div class="cell code" id="cJ09ktl4l3-3">
<div class="sourceCode" id="cb33"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>to_remove <span class="op">=</span> <span class="bu">list</span>(<span class="bu">set</span>(<span class="bu">list</span>(img_index_with_low_information) <span class="op">+</span> <span class="bu">list</span>(dark_img_index) <span class="op">+</span> <span class="bu">list</span>(duplicate_images_index)))</span></code></pre></div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="CQrSuiUyYDqz" data-outputId="7fac395e-e09e-42d6-cac0-5d5a906d73b3">
<div class="sourceCode" id="cb34"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;Number of bad images found : </span><span class="sc">{</span><span class="bu">len</span>(to_remove)<span class="sc">}</span><span class="ss">&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Number of bad images found : 9497
</code></pre>
</div>
</div>
<section id="updated-training-dataset" class="cell markdown"
id="Mr9IjL3Bl9RE">
<h2>Updated Training Dataset</h2>
</section>
<div class="cell code" id="5AhD3QmhX0KH">
<div class="sourceCode" id="cb36"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="co"># new image list</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>reduced_train_images <span class="op">=</span> []</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>reduced_train_labels <span class="op">=</span> []</span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> counter, im, label <span class="kw">in</span> <span class="bu">zip</span>(<span class="bu">range</span>(<span class="bu">len</span>(train_images)), train_images, train_labels):</span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> counter <span class="kw">in</span> to_remove:</span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a>        <span class="cf">continue</span></span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-10"><a href="#cb36-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb36-11"><a href="#cb36-11" aria-hidden="true" tabindex="-1"></a>        reduced_train_images.append(im)</span>
<span id="cb36-12"><a href="#cb36-12" aria-hidden="true" tabindex="-1"></a>        reduced_train_labels.append(label)</span></code></pre></div>
</div>
<section id="normalizing-data" class="cell markdown" id="TjAKR0RhnWuk">
<h2>Normalizing Data</h2>
</section>
<div class="cell code" id="v3ekjyyWnYQq">
<div class="sourceCode" id="cb37"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> normalize_image_np(image):</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>    norm_img <span class="op">=</span> (image <span class="op">-</span> np.<span class="bu">min</span>(image)) <span class="op">/</span> (np.<span class="bu">max</span>(image) <span class="op">-</span> np.<span class="bu">min</span>(image))</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> norm_img</span></code></pre></div>
</div>
<div class="cell code" id="zEW_jdYpnbZi">
<div class="sourceCode" id="cb38"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>train_images <span class="op">=</span> [normalize_image_np(image) <span class="cf">for</span> image <span class="kw">in</span> reduced_train_images]</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>test_images <span class="op">=</span> [normalize_image_np(image) <span class="cf">for</span> image <span class="kw">in</span> test_images]</span></code></pre></div>
</div>
<section
id="---modelling-and-training-using-feed-forward-neural-networks---"
class="cell markdown" id="OreJPhXjQ4GV">
<h1><h1> <b> <center> Modelling and Training using Feed Forward Neural
Networks </center> </b> </h1></h1>
<ul>
<li>Explain what you are trying to do</li>
<li>Add link to the medium article</li>
</ul>
</section>
<section id="create-embeddings-using-eigen-value-decomposition-pca"
class="cell markdown" id="lmXydBpHqup2">
<h2>Create Embeddings using Eigen Value Decomposition (PCA)</h2>
</section>
<div class="cell code" id="FRFdX6Dbq_RE">
<div class="sourceCode" id="cb39"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span></code></pre></div>
</div>
<div class="cell code" id="VD3GyfGEnBZ9">
<div class="sourceCode" id="cb40"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="co"># flattening the train images</span></span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> np.array(train_images).reshape(<span class="dv">50503</span>, <span class="dv">28</span> <span class="op">*</span> <span class="dv">28</span>)</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>Y_train <span class="op">=</span> reduced_train_labels</span></code></pre></div>
</div>
<div class="cell code" id="pwSgqa5NttmS">
<div class="sourceCode" id="cb41"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="co"># flattening the test images</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>X_test <span class="op">=</span> np.array(test_images).reshape(<span class="dv">10000</span>, <span class="dv">28</span> <span class="op">*</span> <span class="dv">28</span>)</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>Y_test <span class="op">=</span> test_labels</span></code></pre></div>
</div>
<div class="cell code" id="4lcvYrKhqyXa">
<div class="sourceCode" id="cb42"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="co"># fitting PCA</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> PCA(n_components <span class="op">=</span> <span class="va">None</span>)</span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>X_new <span class="op">=</span> pca.fit_transform(X_train)</span></code></pre></div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="lrrDIn5qq5h0" data-outputId="f6c2adfe-72e4-425b-d738-28f5ec2816d3">
<div class="sourceCode" id="cb43"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculating new no of features such that 85% of the information in the dataset is retained</span></span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>threshold <span class="op">=</span> <span class="fl">0.85</span></span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>cumulative_variance <span class="op">=</span> np.cumsum(pca.explained_variance_ratio_)</span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a>n_components <span class="op">=</span> np.argmax(cumulative_variance <span class="op">&gt;=</span> threshold) <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(n_components)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>46
</code></pre>
</div>
</div>
<div class="cell markdown" id="3kfVEs1nrNVT">
<p>Hence we can say that we have extracted 195 features out of 28*28
features which retains 95% of the information in the dataset</p>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:444}"
id="FhEYJY3TrQB-" data-outputId="6b5c34ae-3d68-4434-ab94-c7eb18c8edbf">
<div class="sourceCode" id="cb45"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="co"># fitting PCA again to get those 195 features</span></span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> PCA(n_components <span class="op">=</span> n_components)</span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> pca.fit_transform(X_train)</span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(X_train)</span></code></pre></div>
<div class="output execute_result" data-execution_count="87">

  <div id="df-19270ae8-19bd-4f40-b694-6068f5beebc7" class="colab-df-container">
    <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>6</th>
      <th>7</th>
      <th>8</th>
      <th>9</th>
      <th>...</th>
      <th>36</th>
      <th>37</th>
      <th>38</th>
      <th>39</th>
      <th>40</th>
      <th>41</th>
      <th>42</th>
      <th>43</th>
      <th>44</th>
      <th>45</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>-2.208439</td>
      <td>6.145195</td>
      <td>-4.134287</td>
      <td>0.815395</td>
      <td>-0.687318</td>
      <td>-1.570434</td>
      <td>0.025577</td>
      <td>1.012756</td>
      <td>0.656292</td>
      <td>0.215190</td>
      <td>...</td>
      <td>0.116200</td>
      <td>-0.037935</td>
      <td>0.072052</td>
      <td>0.016992</td>
      <td>0.112778</td>
      <td>-0.542487</td>
      <td>-0.337188</td>
      <td>0.450976</td>
      <td>0.025373</td>
      <td>0.296288</td>
    </tr>
    <tr>
      <th>1</th>
      <td>4.859011</td>
      <td>-2.047888</td>
      <td>-2.156956</td>
      <td>0.937111</td>
      <td>1.968101</td>
      <td>3.931461</td>
      <td>-1.683637</td>
      <td>-1.101950</td>
      <td>0.847573</td>
      <td>0.097526</td>
      <td>...</td>
      <td>-0.116398</td>
      <td>0.046202</td>
      <td>-0.093764</td>
      <td>-0.378994</td>
      <td>-0.125859</td>
      <td>0.199978</td>
      <td>-0.132966</td>
      <td>-0.066531</td>
      <td>0.016735</td>
      <td>-0.186447</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-3.259009</td>
      <td>-4.971990</td>
      <td>0.595483</td>
      <td>0.373040</td>
      <td>0.331977</td>
      <td>-0.572131</td>
      <td>0.530642</td>
      <td>0.072513</td>
      <td>0.473651</td>
      <td>0.246415</td>
      <td>...</td>
      <td>0.569309</td>
      <td>0.294184</td>
      <td>-0.353557</td>
      <td>0.188509</td>
      <td>-0.246925</td>
      <td>-0.201548</td>
      <td>-0.331330</td>
      <td>-0.066482</td>
      <td>-0.090224</td>
      <td>-0.187455</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-0.318511</td>
      <td>-4.400119</td>
      <td>0.550357</td>
      <td>1.095033</td>
      <td>0.448122</td>
      <td>0.335890</td>
      <td>-0.305261</td>
      <td>0.025219</td>
      <td>0.442680</td>
      <td>2.009224</td>
      <td>...</td>
      <td>-0.279800</td>
      <td>-0.414233</td>
      <td>-0.084571</td>
      <td>0.215792</td>
      <td>-0.283175</td>
      <td>-0.194854</td>
      <td>-0.277283</td>
      <td>0.397176</td>
      <td>0.253820</td>
      <td>0.061514</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2.592005</td>
      <td>-4.669180</td>
      <td>-3.178935</td>
      <td>-1.135868</td>
      <td>-1.698617</td>
      <td>-0.518074</td>
      <td>1.712628</td>
      <td>0.473259</td>
      <td>1.015055</td>
      <td>0.100512</td>
      <td>...</td>
      <td>0.431989</td>
      <td>0.360399</td>
      <td>-0.109942</td>
      <td>0.155513</td>
      <td>0.031614</td>
      <td>0.103302</td>
      <td>0.046732</td>
      <td>-0.264479</td>
      <td>0.045781</td>
      <td>-0.385623</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>50498</th>
      <td>-6.586370</td>
      <td>0.447454</td>
      <td>0.052691</td>
      <td>-1.602056</td>
      <td>0.221330</td>
      <td>0.116083</td>
      <td>-0.715780</td>
      <td>-1.499584</td>
      <td>0.016413</td>
      <td>-0.119027</td>
      <td>...</td>
      <td>0.129045</td>
      <td>-0.509618</td>
      <td>0.778261</td>
      <td>-0.463077</td>
      <td>0.011430</td>
      <td>-0.376195</td>
      <td>-0.256612</td>
      <td>0.082516</td>
      <td>0.276708</td>
      <td>0.277510</td>
    </tr>
    <tr>
      <th>50499</th>
      <td>0.208006</td>
      <td>-1.967429</td>
      <td>1.863021</td>
      <td>0.868961</td>
      <td>-1.563636</td>
      <td>-0.547244</td>
      <td>-1.121710</td>
      <td>0.551923</td>
      <td>-0.928694</td>
      <td>0.165407</td>
      <td>...</td>
      <td>0.304787</td>
      <td>0.591432</td>
      <td>-0.325304</td>
      <td>0.093853</td>
      <td>0.054438</td>
      <td>0.087310</td>
      <td>-0.085039</td>
      <td>-0.431965</td>
      <td>0.213420</td>
      <td>0.327283</td>
    </tr>
    <tr>
      <th>50500</th>
      <td>0.801886</td>
      <td>7.768272</td>
      <td>-1.141110</td>
      <td>-2.367468</td>
      <td>-0.231923</td>
      <td>1.700106</td>
      <td>2.303612</td>
      <td>3.891102</td>
      <td>-0.974718</td>
      <td>0.215461</td>
      <td>...</td>
      <td>0.189357</td>
      <td>0.258287</td>
      <td>0.074399</td>
      <td>-0.031048</td>
      <td>0.087975</td>
      <td>0.235431</td>
      <td>0.408168</td>
      <td>0.520098</td>
      <td>-0.558213</td>
      <td>-0.244509</td>
    </tr>
    <tr>
      <th>50501</th>
      <td>2.882347</td>
      <td>-4.559922</td>
      <td>-2.236861</td>
      <td>-1.986208</td>
      <td>-0.471375</td>
      <td>-1.050567</td>
      <td>0.364239</td>
      <td>0.116209</td>
      <td>-0.994251</td>
      <td>-1.611482</td>
      <td>...</td>
      <td>-0.169781</td>
      <td>-0.100659</td>
      <td>0.523275</td>
      <td>-0.128593</td>
      <td>1.071321</td>
      <td>0.007489</td>
      <td>0.927778</td>
      <td>-0.118338</td>
      <td>-0.018247</td>
      <td>0.304502</td>
    </tr>
    <tr>
      <th>50502</th>
      <td>-3.632419</td>
      <td>-3.134780</td>
      <td>1.879421</td>
      <td>1.043437</td>
      <td>1.352628</td>
      <td>1.692753</td>
      <td>-0.166043</td>
      <td>0.166944</td>
      <td>-0.031685</td>
      <td>-0.051316</td>
      <td>...</td>
      <td>-0.171564</td>
      <td>-0.248723</td>
      <td>0.248141</td>
      <td>0.431845</td>
      <td>-0.015723</td>
      <td>0.050371</td>
      <td>-0.202060</td>
      <td>-0.250364</td>
      <td>0.067405</td>
      <td>0.241967</td>
    </tr>
  </tbody>
</table>
<p>50503 rows Ã— 46 columns</p>
</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-19270ae8-19bd-4f40-b694-6068f5beebc7')"
            title="Convert this dataframe to an interactive table."
            style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"/>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-19270ae8-19bd-4f40-b694-6068f5beebc7 button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-19270ae8-19bd-4f40-b694-6068f5beebc7');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


<div id="df-0acd13f4-3355-4c57-9d9f-4c2523a50a73">
  <button class="colab-df-quickchart" onclick="quickchart('df-0acd13f4-3355-4c57-9d9f-4c2523a50a73')"
            title="Suggest charts"
            style="display:none;">

<svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
     width="24px">
    <g>
        <path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z"/>
    </g>
</svg>
  </button>

<style>
  .colab-df-quickchart {
      --bg-color: #E8F0FE;
      --fill-color: #1967D2;
      --hover-bg-color: #E2EBFA;
      --hover-fill-color: #174EA6;
      --disabled-fill-color: #AAA;
      --disabled-bg-color: #DDD;
  }

  [theme=dark] .colab-df-quickchart {
      --bg-color: #3B4455;
      --fill-color: #D2E3FC;
      --hover-bg-color: #434B5C;
      --hover-fill-color: #FFFFFF;
      --disabled-bg-color: #3B4455;
      --disabled-fill-color: #666;
  }

  .colab-df-quickchart {
    background-color: var(--bg-color);
    border: none;
    border-radius: 50%;
    cursor: pointer;
    display: none;
    fill: var(--fill-color);
    height: 32px;
    padding: 0;
    width: 32px;
  }

  .colab-df-quickchart:hover {
    background-color: var(--hover-bg-color);
    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);
    fill: var(--button-hover-fill-color);
  }

  .colab-df-quickchart-complete:disabled,
  .colab-df-quickchart-complete:disabled:hover {
    background-color: var(--disabled-bg-color);
    fill: var(--disabled-fill-color);
    box-shadow: none;
  }

  .colab-df-spinner {
    border: 2px solid var(--fill-color);
    border-color: transparent;
    border-bottom-color: var(--fill-color);
    animation:
      spin 1s steps(1) infinite;
  }

  @keyframes spin {
    0% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
      border-left-color: var(--fill-color);
    }
    20% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    30% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
      border-right-color: var(--fill-color);
    }
    40% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    60% {
      border-color: transparent;
      border-right-color: var(--fill-color);
    }
    80% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-bottom-color: var(--fill-color);
    }
    90% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
    }
  }
</style>

  <script>
    async function quickchart(key) {
      const quickchartButtonEl =
        document.querySelector('#' + key + ' button');
      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.
      quickchartButtonEl.classList.add('colab-df-spinner');
      try {
        const charts = await google.colab.kernel.invokeFunction(
            'suggestCharts', [key], {});
      } catch (error) {
        console.error('Error during call to suggestCharts:', error);
      }
      quickchartButtonEl.classList.remove('colab-df-spinner');
      quickchartButtonEl.classList.add('colab-df-quickchart-complete');
    }
    (() => {
      let quickchartButtonEl =
        document.querySelector('#df-0acd13f4-3355-4c57-9d9f-4c2523a50a73 button');
      quickchartButtonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';
    })();
  </script>
</div>

    </div>
  </div>

</div>
</div>
<div class="cell code" id="p7uYN1PgtjnZ">
<div class="sourceCode" id="cb46"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a>X_test <span class="op">=</span> pca.fit_transform(X_test)</span></code></pre></div>
</div>
<section id="visualization" class="cell markdown" id="y-2zPtIerYeU">
<h2>Visualization</h2>
</section>
<div class="cell code" id="43ahQQ9YraRq">
<div class="sourceCode" id="cb47"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="co"># creating 2d features to plot a diagram</span></span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> PCA(n_components <span class="op">=</span> <span class="dv">2</span>)</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a>X_new_temp <span class="op">=</span> pca.fit_transform(X_train)</span></code></pre></div>
</div>
<div class="cell code" id="DZM2cCf-raO3">
<div class="sourceCode" id="cb48"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>dataset <span class="op">=</span> pd.DataFrame(X_new_temp, columns<span class="op">=</span>[<span class="st">&#39;Feature 1&#39;</span>, <span class="st">&#39;Feature 2&#39;</span>])</span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>dataset[<span class="st">&#39;Label&#39;</span>] <span class="op">=</span> reduced_train_labels</span></code></pre></div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:718}"
id="9HsKVgdEraLA" data-outputId="690009ff-579d-411c-ab52-06f0fc69ec39">
<div class="sourceCode" id="cb49"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">8</span>))</span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>colors <span class="op">=</span> plt.cm.tab10(np.linspace(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">10</span>))  <span class="co"># Use a colormap to get distinct colors for each class</span></span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> class_value <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10</span>):</span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a>    subset <span class="op">=</span> dataset[dataset[<span class="st">&#39;Label&#39;</span>] <span class="op">==</span> class_value]</span>
<span id="cb49-6"><a href="#cb49-6" aria-hidden="true" tabindex="-1"></a>    plt.scatter(subset[<span class="st">&#39;Feature 1&#39;</span>], subset[<span class="st">&#39;Feature 2&#39;</span>], label<span class="op">=</span><span class="ss">f&#39;Class </span><span class="sc">{</span>class_value<span class="sc">}</span><span class="ss">&#39;</span>, color<span class="op">=</span>colors[class_value])</span>
<span id="cb49-7"><a href="#cb49-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-8"><a href="#cb49-8" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Classification Dataset with 2 Features and 10 Classes&#39;</span>)</span>
<span id="cb49-9"><a href="#cb49-9" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;Feature 1&#39;</span>)</span>
<span id="cb49-10"><a href="#cb49-10" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Feature 2&#39;</span>)</span>
<span id="cb49-11"><a href="#cb49-11" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb49-12"><a href="#cb49-12" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb49-13"><a href="#cb49-13" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_889211e4574a44c3907c85a1cc095ae7/00a822d32309eade626da9697609981498a7d2d3.png" /></p>
</div>
</div>
<section id="independent-feature-correlation-analysis"
class="cell markdown" id="xJeNPuGFr4yB">
<h2>Independent Feature Correlation Analysis</h2>
<p>Using this we can decide which feature to drop. If two features are
highly correlated then we can drop one of them since they are almost
similar features</p>
</section>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:1000}"
id="8dzNglZ4sBD7" data-outputId="f677b9ba-01bb-445f-fe48-361ca0068c5c">
<div class="sourceCode" id="cb50"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>numerical_features <span class="op">=</span> pd.DataFrame(X_train).select_dtypes(include<span class="op">=</span>np.number)</span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the correlation matrix</span></span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a>correlation_matrix <span class="op">=</span> numerical_features.corr()</span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-6"><a href="#cb50-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Mask the upper triangle for better readability</span></span>
<span id="cb50-7"><a href="#cb50-7" aria-hidden="true" tabindex="-1"></a>mask <span class="op">=</span> np.triu(np.ones_like(correlation_matrix, dtype<span class="op">=</span><span class="bu">bool</span>))</span>
<span id="cb50-8"><a href="#cb50-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-9"><a href="#cb50-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the heatmap</span></span>
<span id="cb50-10"><a href="#cb50-10" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">100</span>, <span class="dv">100</span>))</span>
<span id="cb50-11"><a href="#cb50-11" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb50-12"><a href="#cb50-12" aria-hidden="true" tabindex="-1"></a>sns.heatmap(correlation_matrix, mask<span class="op">=</span>mask, annot<span class="op">=</span><span class="va">False</span>, cmap<span class="op">=</span><span class="st">&#39;coolwarm&#39;</span>, fmt<span class="op">=</span><span class="st">&quot;.2f&quot;</span>, linewidths<span class="op">=</span><span class="fl">.5</span>)</span>
<span id="cb50-13"><a href="#cb50-13" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Correlation Matrix of Numerical Features in Boston Housing Data&#39;</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb50-14"><a href="#cb50-14" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_889211e4574a44c3907c85a1cc095ae7/7f7f01a2ff99fb8a5f44fd25ca075cd3bd9ea55b.png" /></p>
</div>
</div>
<section id="outlier-handling" class="cell markdown" id="F9uAoCbYsSjy">
<h2>Outlier Handling</h2>
<p>Predicting outliers using Isolation Forest</p>
</section>
<div class="cell code" id="sLfoMNUMsA9h">
<div class="sourceCode" id="cb51"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> IsolationForest</span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> IsolationForest(random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a>clf.fit(X_train)</span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a>outlier_pred <span class="op">=</span> clf.predict(X_train)</span></code></pre></div>
</div>
<div class="cell markdown" id="jWIjrM4AshPW">
<p>2D visualization after removing outliers</p>
</div>
<div class="cell code" id="WNr7NQyYsk0V">
<div class="sourceCode" id="cb52"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>dataset[<span class="st">&#39;outlier&#39;</span>] <span class="op">=</span> outlier_pred <span class="co"># adding a outlier col in the dataset</span></span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a>dataset[<span class="st">&#39;Label&#39;</span>] <span class="op">=</span> dataset[<span class="st">&#39;Label&#39;</span>].where(dataset[<span class="st">&#39;outlier&#39;</span>] <span class="op">!=</span> <span class="op">-</span><span class="dv">1</span>, <span class="dv">10</span>) <span class="co"># creating outlier points as class 10</span></span></code></pre></div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:718}"
id="JuN_p-blslh_" data-outputId="8eec047e-7f3a-4f3d-8b6c-ef15576fb47d">
<div class="sourceCode" id="cb53"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">8</span>))</span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a>colors <span class="op">=</span> plt.cm.tab10(np.linspace(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">11</span>))  <span class="co"># Use a colormap to get distinct colors for each class</span></span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> class_value <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">11</span>):</span>
<span id="cb53-5"><a href="#cb53-5" aria-hidden="true" tabindex="-1"></a>    subset <span class="op">=</span> dataset[dataset[<span class="st">&#39;Label&#39;</span>] <span class="op">==</span> class_value]</span>
<span id="cb53-6"><a href="#cb53-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> class_value <span class="op">==</span> <span class="dv">10</span>:</span>
<span id="cb53-7"><a href="#cb53-7" aria-hidden="true" tabindex="-1"></a>      plt.scatter(subset[<span class="st">&#39;Feature 1&#39;</span>], subset[<span class="st">&#39;Feature 2&#39;</span>], label<span class="op">=</span><span class="ss">f&#39;Outliers&#39;</span>, color<span class="op">=</span><span class="st">&#39;black&#39;</span>)</span>
<span id="cb53-8"><a href="#cb53-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb53-9"><a href="#cb53-9" aria-hidden="true" tabindex="-1"></a>      plt.scatter(subset[<span class="st">&#39;Feature 1&#39;</span>], subset[<span class="st">&#39;Feature 2&#39;</span>], label<span class="op">=</span><span class="ss">f&#39;Class </span><span class="sc">{</span>class_value<span class="sc">}</span><span class="ss">&#39;</span>, color<span class="op">=</span>colors[class_value])</span>
<span id="cb53-10"><a href="#cb53-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-11"><a href="#cb53-11" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Classification Dataset with 2 Features and 10 Classes&#39;</span>)</span>
<span id="cb53-12"><a href="#cb53-12" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;Feature 1&#39;</span>)</span>
<span id="cb53-13"><a href="#cb53-13" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Feature 2&#39;</span>)</span>
<span id="cb53-14"><a href="#cb53-14" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb53-15"><a href="#cb53-15" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb53-16"><a href="#cb53-16" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_889211e4574a44c3907c85a1cc095ae7/727f5a8c13b77c057f803c3d1122462706937f5f.png" /></p>
</div>
</div>
<div class="cell markdown" id="lPO0Qk5ispb5">
<p>Note : In 2d plot they might not look at outliers since we have
reduced the dimensions but in the original dimensions they are outliers
based on isolation forest method</p>
</div>
<div class="cell markdown" id="N3QPba48srkz">
<p>Dataset after removal of outliers</p>
</div>
<div class="cell code" id="Z56EZP7zslei">
<div class="sourceCode" id="cb54"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>train_df <span class="op">=</span> pd.DataFrame(X_train)</span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a>train_df[<span class="st">&#39;Label&#39;</span>] <span class="op">=</span> Y_train</span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a>train_df[<span class="st">&#39;outlier&#39;</span>] <span class="op">=</span> outlier_pred</span></code></pre></div>
</div>
<div class="cell code" id="AtIBdxA0slbP">
<div class="sourceCode" id="cb55"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a>train_df <span class="op">=</span> train_df[train_df[<span class="st">&#39;outlier&#39;</span>] <span class="op">!=</span> <span class="op">-</span><span class="dv">1</span>]</span></code></pre></div>
</div>
<div class="cell code" id="DxFtr9x_slX7">
<div class="sourceCode" id="cb56"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> np.array(train_df.drop([<span class="st">&#39;Label&#39;</span>, <span class="st">&#39;outlier&#39;</span>], axis<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a>Y_train <span class="op">=</span> np.array(train_df[<span class="st">&#39;Label&#39;</span>])</span></code></pre></div>
</div>
<section id="creating-dataloaders" class="cell markdown"
id="-10i8tjMY12B">
<h2>Creating Dataloaders</h2>
</section>
<div class="cell code" id="zxoG3aBlu0zS">
<div class="sourceCode" id="cb57"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a>x_train <span class="op">=</span> np.array(X_train)</span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a>y_train <span class="op">=</span> np.array(Y_train)</span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a>x_test <span class="op">=</span> np.array(X_test)</span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a>y_test <span class="op">=</span> np.array(Y_test)</span></code></pre></div>
</div>
<div class="cell code" id="NS9BwB50gHv2">
<div class="sourceCode" id="cb58"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a>transform <span class="op">=</span> transforms.Compose([transforms.ToTensor()])</span></code></pre></div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="0E8pphRhQ4GU" data-outputId="ee0c85fd-b018-4d30-fcd1-1c7c985109b0"
data-vscode="{&quot;languageId&quot;:&quot;plaintext&quot;}">
<div class="sourceCode" id="cb59"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a>reduced_train_images_tensor <span class="op">=</span> torch.stack([transform(Image.fromarray(img)) <span class="cf">for</span> img <span class="kw">in</span> x_train])</span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a>reduced_train_labels_tensor <span class="op">=</span> torch.tensor(np.array(y_train), dtype<span class="op">=</span>torch.<span class="bu">long</span>)</span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a>train_dataset <span class="op">=</span> TensorDataset(reduced_train_images_tensor, reduced_train_labels_tensor)</span>
<span id="cb59-4"><a href="#cb59-4" aria-hidden="true" tabindex="-1"></a>train_dataloader <span class="op">=</span> DataLoader(train_dataset, batch_size<span class="op">=</span><span class="dv">32</span>, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb59-5"><a href="#cb59-5" aria-hidden="true" tabindex="-1"></a>train_features_batch, train_labels_batch <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(train_dataloader))</span>
<span id="cb59-6"><a href="#cb59-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-7"><a href="#cb59-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Features Batch Size </span><span class="sc">{</span>train_features_batch<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb59-8"><a href="#cb59-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Labels Batch Size </span><span class="sc">{</span>train_labels_batch<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb59-9"><a href="#cb59-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Length of train dataloader: </span><span class="sc">{</span><span class="bu">len</span>(train_dataloader)<span class="sc">}</span><span class="ss"> batches of 32&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Features Batch Size torch.Size([32, 1, 46, 1])
Labels Batch Size torch.Size([32])
Length of train dataloader: 1529 batches of 32
</code></pre>
</div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="pGeQJnZiQ4GV" data-outputId="c5ee02bb-3fcc-45ee-dcd4-62d761728684"
data-vscode="{&quot;languageId&quot;:&quot;plaintext&quot;}">
<div class="sourceCode" id="cb61"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a>reduced_test_images_tensor <span class="op">=</span> torch.stack([transform(Image.fromarray(img)) <span class="cf">for</span> img <span class="kw">in</span> x_test])</span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a>reduced_test_labels_tensor <span class="op">=</span> torch.tensor(np.array(y_test), dtype<span class="op">=</span>torch.<span class="bu">long</span>)</span>
<span id="cb61-3"><a href="#cb61-3" aria-hidden="true" tabindex="-1"></a>test_dataset <span class="op">=</span> TensorDataset(reduced_test_images_tensor, reduced_test_labels_tensor)</span>
<span id="cb61-4"><a href="#cb61-4" aria-hidden="true" tabindex="-1"></a>test_dataloader <span class="op">=</span> DataLoader(test_dataset, batch_size<span class="op">=</span><span class="dv">32</span>, shuffle<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb61-5"><a href="#cb61-5" aria-hidden="true" tabindex="-1"></a>test_features_batch, test_labels_batch <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(test_dataloader))</span>
<span id="cb61-6"><a href="#cb61-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-7"><a href="#cb61-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Features Batch Size </span><span class="sc">{</span>test_features_batch<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb61-8"><a href="#cb61-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Labels Batch Size </span><span class="sc">{</span>test_labels_batch<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb61-9"><a href="#cb61-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Length of train dataloader: </span><span class="sc">{</span><span class="bu">len</span>(test_dataloader)<span class="sc">}</span><span class="ss"> batches of 32&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Features Batch Size torch.Size([32, 1, 46, 1])
Labels Batch Size torch.Size([32])
Length of train dataloader: 313 batches of 32
</code></pre>
</div>
</div>
<section id="model-architecture" class="cell markdown"
id="Y7QsaycbTfoF">
<h2>Model Architecture</h2>
<ul>
<li>Include an image of the model that you are trying to build</li>
</ul>
</section>
<div class="cell code" id="Yynzm86UQ4GV"
data-vscode="{&quot;languageId&quot;:&quot;plaintext&quot;}">
<div class="sourceCode" id="cb63"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="co"># defining model architecture</span></span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> FFNN_Model(nn.Module):</span>
<span id="cb63-3"><a href="#cb63-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-4"><a href="#cb63-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb63-5"><a href="#cb63-5" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb63-6"><a href="#cb63-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.layer_stack <span class="op">=</span> nn.Sequential(</span>
<span id="cb63-7"><a href="#cb63-7" aria-hidden="true" tabindex="-1"></a>            nn.Flatten(),</span>
<span id="cb63-8"><a href="#cb63-8" aria-hidden="true" tabindex="-1"></a>            nn.Linear(in_features<span class="op">=</span><span class="dv">46</span>, out_features<span class="op">=</span><span class="dv">392</span>),nn.ReLU(),</span>
<span id="cb63-9"><a href="#cb63-9" aria-hidden="true" tabindex="-1"></a>            nn.Linear(in_features<span class="op">=</span><span class="dv">392</span>, out_features<span class="op">=</span><span class="dv">196</span>),nn.ReLU(),</span>
<span id="cb63-10"><a href="#cb63-10" aria-hidden="true" tabindex="-1"></a>            nn.Linear(in_features<span class="op">=</span><span class="dv">196</span>, out_features<span class="op">=</span><span class="dv">98</span>),nn.ReLU(),</span>
<span id="cb63-11"><a href="#cb63-11" aria-hidden="true" tabindex="-1"></a>            nn.Linear(in_features<span class="op">=</span><span class="dv">98</span>, out_features<span class="op">=</span><span class="dv">49</span>),nn.ReLU(),</span>
<span id="cb63-12"><a href="#cb63-12" aria-hidden="true" tabindex="-1"></a>            nn.Linear(in_features<span class="op">=</span><span class="dv">49</span>, out_features<span class="op">=</span><span class="dv">20</span>),nn.ReLU(),</span>
<span id="cb63-13"><a href="#cb63-13" aria-hidden="true" tabindex="-1"></a>            nn.Linear(in_features<span class="op">=</span><span class="dv">20</span>, out_features<span class="op">=</span><span class="dv">10</span>),nn.ReLU()</span>
<span id="cb63-14"><a href="#cb63-14" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb63-15"><a href="#cb63-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-16"><a href="#cb63-16" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x: torch.Tensor):</span>
<span id="cb63-17"><a href="#cb63-17" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.layer_stack(x)</span>
<span id="cb63-18"><a href="#cb63-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-19"><a href="#cb63-19" aria-hidden="true" tabindex="-1"></a><span class="co"># instantiating the model</span></span>
<span id="cb63-20"><a href="#cb63-20" aria-hidden="true" tabindex="-1"></a>ffnn_model <span class="op">=</span> FFNN_Model().to(device)</span></code></pre></div>
</div>
<section id="training" class="cell markdown" id="ki4Ne8zrTspz">
<h2>Training</h2>
</section>
<div class="cell code" id="jM_twECro0i4">
<div class="sourceCode" id="cb64"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="co"># defining evaluation metric for model =&gt; since we have a balanced dataset we will be using accuracy for our model</span></span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> accuracy_fn(y_true, y_pred):</span>
<span id="cb64-3"><a href="#cb64-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (torch.eq(y_true, y_pred).<span class="bu">sum</span>().item() <span class="op">/</span> <span class="bu">len</span>(y_pred)) <span class="op">*</span> <span class="dv">100</span></span></code></pre></div>
</div>
<div class="cell code" id="04FUpw_IQ4GV"
data-vscode="{&quot;languageId&quot;:&quot;plaintext&quot;}">
<div class="sourceCode" id="cb65"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_step(model, train_dataloader, optimizer):</span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-3"><a href="#cb65-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># defining optimizer for the model</span></span>
<span id="cb65-4"><a href="#cb65-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> optimizer <span class="op">==</span> <span class="st">&#39;SGD&#39;</span>:</span>
<span id="cb65-5"><a href="#cb65-5" aria-hidden="true" tabindex="-1"></a>        optimizer <span class="op">=</span> torch.optim.SGD(params<span class="op">=</span>model.parameters(),lr<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb65-6"><a href="#cb65-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-7"><a href="#cb65-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># defining loss function for model</span></span>
<span id="cb65-8"><a href="#cb65-8" aria-hidden="true" tabindex="-1"></a>    loss_fn <span class="op">=</span> nn.CrossEntropyLoss()</span>
<span id="cb65-9"><a href="#cb65-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-10"><a href="#cb65-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># housekeeping stuff</span></span>
<span id="cb65-11"><a href="#cb65-11" aria-hidden="true" tabindex="-1"></a>    train_loss_list <span class="op">=</span> []</span>
<span id="cb65-12"><a href="#cb65-12" aria-hidden="true" tabindex="-1"></a>    train_acc_list <span class="op">=</span> []</span>
<span id="cb65-13"><a href="#cb65-13" aria-hidden="true" tabindex="-1"></a>    test_loss_list <span class="op">=</span> []</span>
<span id="cb65-14"><a href="#cb65-14" aria-hidden="true" tabindex="-1"></a>    test_acc_list <span class="op">=</span> []</span>
<span id="cb65-15"><a href="#cb65-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-16"><a href="#cb65-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> tqdm(<span class="bu">range</span>(<span class="dv">50</span>)):</span>
<span id="cb65-17"><a href="#cb65-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-18"><a href="#cb65-18" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f&quot;Epoch: </span><span class="sc">{</span>epoch<span class="sc">}</span><span class="ch">\n</span><span class="ss">-------&quot;</span>)</span>
<span id="cb65-19"><a href="#cb65-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-20"><a href="#cb65-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-21"><a href="#cb65-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-22"><a href="#cb65-22" aria-hidden="true" tabindex="-1"></a>        <span class="co">&#39;&#39;&#39;</span></span>
<span id="cb65-23"><a href="#cb65-23" aria-hidden="true" tabindex="-1"></a><span class="co">        TRAINING</span></span>
<span id="cb65-24"><a href="#cb65-24" aria-hidden="true" tabindex="-1"></a><span class="co">        &#39;&#39;&#39;</span></span>
<span id="cb65-25"><a href="#cb65-25" aria-hidden="true" tabindex="-1"></a>        train_loss, train_acc <span class="op">=</span> <span class="dv">0</span>, <span class="dv">0</span></span>
<span id="cb65-26"><a href="#cb65-26" aria-hidden="true" tabindex="-1"></a>        model.train()</span>
<span id="cb65-27"><a href="#cb65-27" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> batch, (X, y) <span class="kw">in</span> <span class="bu">enumerate</span>(train_dataloader):</span>
<span id="cb65-28"><a href="#cb65-28" aria-hidden="true" tabindex="-1"></a>            X, y <span class="op">=</span> X.to(device), y.to(device)</span>
<span id="cb65-29"><a href="#cb65-29" aria-hidden="true" tabindex="-1"></a>            y_pred <span class="op">=</span> model(X) <span class="co">#Forward pass</span></span>
<span id="cb65-30"><a href="#cb65-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-31"><a href="#cb65-31" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> loss_fn(y_pred, y) <span class="co"># Calculate loss (per batch)</span></span>
<span id="cb65-32"><a href="#cb65-32" aria-hidden="true" tabindex="-1"></a>            acc <span class="op">=</span> accuracy_fn(y_true<span class="op">=</span>y,y_pred<span class="op">=</span>y_pred.argmax(dim<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb65-33"><a href="#cb65-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-34"><a href="#cb65-34" aria-hidden="true" tabindex="-1"></a>            train_loss <span class="op">+=</span> loss <span class="co"># accumulatively add up the loss per epoch</span></span>
<span id="cb65-35"><a href="#cb65-35" aria-hidden="true" tabindex="-1"></a>            train_acc <span class="op">+=</span> acc <span class="co"># Go from logits -&gt; pred labels</span></span>
<span id="cb65-36"><a href="#cb65-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-37"><a href="#cb65-37" aria-hidden="true" tabindex="-1"></a>            optimizer.zero_grad() <span class="co"># Optimizer zero grad</span></span>
<span id="cb65-38"><a href="#cb65-38" aria-hidden="true" tabindex="-1"></a>            loss.backward() <span class="co"># Loss backward</span></span>
<span id="cb65-39"><a href="#cb65-39" aria-hidden="true" tabindex="-1"></a>            optimizer.step() <span class="co"># Optimizer step</span></span>
<span id="cb65-40"><a href="#cb65-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-41"><a href="#cb65-41" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Print out how many samples have been seen</span></span>
<span id="cb65-42"><a href="#cb65-42" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> batch <span class="op">%</span> <span class="dv">400</span> <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb65-43"><a href="#cb65-43" aria-hidden="true" tabindex="-1"></a>                <span class="bu">print</span>(<span class="ss">f&quot;Looked at </span><span class="sc">{</span>batch <span class="op">*</span> <span class="bu">len</span>(X)<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span><span class="bu">len</span>(train_dataloader.dataset)<span class="sc">}</span><span class="ss"> samples&quot;</span>)</span>
<span id="cb65-44"><a href="#cb65-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-45"><a href="#cb65-45" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Divide total train loss by length of train dataloader (average loss per batch per epoch)</span></span>
<span id="cb65-46"><a href="#cb65-46" aria-hidden="true" tabindex="-1"></a>        train_loss <span class="op">/=</span> <span class="bu">len</span>(train_dataloader)</span>
<span id="cb65-47"><a href="#cb65-47" aria-hidden="true" tabindex="-1"></a>        train_acc <span class="op">/=</span> <span class="bu">len</span>(train_dataloader)</span>
<span id="cb65-48"><a href="#cb65-48" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f&quot;Train loss: </span><span class="sc">{</span>train_loss<span class="sc">:.5f}</span><span class="ss"> | Train accuracy: </span><span class="sc">{</span>train_acc<span class="sc">:.2f}</span><span class="ss">%&quot;</span>)</span>
<span id="cb65-49"><a href="#cb65-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-50"><a href="#cb65-50" aria-hidden="true" tabindex="-1"></a>        <span class="co"># housekeeping stuff</span></span>
<span id="cb65-51"><a href="#cb65-51" aria-hidden="true" tabindex="-1"></a>        train_loss_list.append(train_loss)</span>
<span id="cb65-52"><a href="#cb65-52" aria-hidden="true" tabindex="-1"></a>        train_acc_list.append(train_acc)</span>
<span id="cb65-53"><a href="#cb65-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-54"><a href="#cb65-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-55"><a href="#cb65-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-56"><a href="#cb65-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-57"><a href="#cb65-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-58"><a href="#cb65-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-59"><a href="#cb65-59" aria-hidden="true" tabindex="-1"></a>        <span class="co">&#39;&#39;&#39;</span></span>
<span id="cb65-60"><a href="#cb65-60" aria-hidden="true" tabindex="-1"></a><span class="co">        </span><span class="al">TESTING</span></span>
<span id="cb65-61"><a href="#cb65-61" aria-hidden="true" tabindex="-1"></a><span class="co">        &#39;&#39;&#39;</span></span>
<span id="cb65-62"><a href="#cb65-62" aria-hidden="true" tabindex="-1"></a>        test_loss, test_acc <span class="op">=</span> <span class="dv">0</span>, <span class="dv">0</span></span>
<span id="cb65-63"><a href="#cb65-63" aria-hidden="true" tabindex="-1"></a>        model.<span class="bu">eval</span>()</span>
<span id="cb65-64"><a href="#cb65-64" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> torch.inference_mode():</span>
<span id="cb65-65"><a href="#cb65-65" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> X, y <span class="kw">in</span> test_dataloader:</span>
<span id="cb65-66"><a href="#cb65-66" aria-hidden="true" tabindex="-1"></a>                X, y <span class="op">=</span> X.to(device), y.to(device)</span>
<span id="cb65-67"><a href="#cb65-67" aria-hidden="true" tabindex="-1"></a>                test_pred <span class="op">=</span> model(X) <span class="co"># Forward pass</span></span>
<span id="cb65-68"><a href="#cb65-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-69"><a href="#cb65-69" aria-hidden="true" tabindex="-1"></a>                loss <span class="op">=</span> loss_fn(test_pred, y)</span>
<span id="cb65-70"><a href="#cb65-70" aria-hidden="true" tabindex="-1"></a>                acc <span class="op">=</span> accuracy_fn(y_true<span class="op">=</span>y,y_pred<span class="op">=</span>test_pred.argmax(dim<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb65-71"><a href="#cb65-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-72"><a href="#cb65-72" aria-hidden="true" tabindex="-1"></a>                test_loss <span class="op">+=</span> loss</span>
<span id="cb65-73"><a href="#cb65-73" aria-hidden="true" tabindex="-1"></a>                test_acc <span class="op">+=</span> acc</span>
<span id="cb65-74"><a href="#cb65-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-75"><a href="#cb65-75" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Calculations on test metrics need to happen inside torch.inference_mode()</span></span>
<span id="cb65-76"><a href="#cb65-76" aria-hidden="true" tabindex="-1"></a>            test_loss <span class="op">/=</span> <span class="bu">len</span>(test_dataloader)</span>
<span id="cb65-77"><a href="#cb65-77" aria-hidden="true" tabindex="-1"></a>            test_acc <span class="op">/=</span> <span class="bu">len</span>(test_dataloader)</span>
<span id="cb65-78"><a href="#cb65-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-79"><a href="#cb65-79" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f&quot;Test loss: </span><span class="sc">{</span>test_loss<span class="sc">:.5f}</span><span class="ss">  | Test acc: </span><span class="sc">{</span>test_acc<span class="sc">:.2f}</span><span class="ss">%</span><span class="ch">\n</span><span class="ss">&quot;</span>)</span>
<span id="cb65-80"><a href="#cb65-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-81"><a href="#cb65-81" aria-hidden="true" tabindex="-1"></a>        <span class="co"># housekeeping stuff</span></span>
<span id="cb65-82"><a href="#cb65-82" aria-hidden="true" tabindex="-1"></a>        test_loss_list.append(test_loss)</span>
<span id="cb65-83"><a href="#cb65-83" aria-hidden="true" tabindex="-1"></a>        test_acc_list.append(test_acc)</span>
<span id="cb65-84"><a href="#cb65-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-85"><a href="#cb65-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-86"><a href="#cb65-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-87"><a href="#cb65-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-88"><a href="#cb65-88" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> train_loss_list, train_acc_list, test_loss_list, test_acc_list</span></code></pre></div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:1000,&quot;referenced_widgets&quot;:[&quot;6ac0078213ba4405b62923e2c2c9f22c&quot;,&quot;f0aee9059cfc4186adbeae586439684d&quot;,&quot;43bcf0b83a614d7abd7dff1e65158dad&quot;,&quot;b587af9337f844749ba7edcfe9224f46&quot;,&quot;29a91337f524425bb41792a477f6dbba&quot;,&quot;7960a129d3df4982a0ee3b22f985a21f&quot;,&quot;d2674525b3ab403983a94d4e125d8c08&quot;,&quot;19597a7f93544a6ebb212a1230c8b160&quot;,&quot;fd9276d77aaf434a9f7cf8b7666228ae&quot;,&quot;3a1f8dda79ef4f24a85cac2989ae8e41&quot;,&quot;7820bde596354807a8262e201c180eb1&quot;]}"
id="aU69CGWaQ4GV" data-outputId="356ecd3b-8803-4e20-dbb9-2a69703c069d"
data-vscode="{&quot;languageId&quot;:&quot;plaintext&quot;}">
<div class="sourceCode" id="cb66"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a>train_loss_ffnn, train_acc_ffnn, test_loss_ffnn, test_acc_ffnn <span class="op">=</span> train_step(ffnn_model, train_dataloader, <span class="st">&#39;SGD&#39;</span>)</span></code></pre></div>
<div class="output display_data">
<div class="sourceCode" id="cb67"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;6ac0078213ba4405b62923e2c2c9f22c&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stdout">
<pre><code>Epoch: 0
-------
Looked at 0/48928 samples
Looked at 12800/48928 samples
Looked at 25600/48928 samples
Looked at 38400/48928 samples
Train loss: 1.73103 | Train accuracy: 36.07%
Test loss: 2.96241  | Test acc: 9.47%

Epoch: 1
-------
Looked at 0/48928 samples
Looked at 12800/48928 samples
Looked at 25600/48928 samples
Looked at 38400/48928 samples
Train loss: 1.26976 | Train accuracy: 51.66%
Test loss: 3.49580  | Test acc: 12.95%

Epoch: 2
-------
Looked at 0/48928 samples
Looked at 12800/48928 samples
Looked at 25600/48928 samples
Looked at 38400/48928 samples
Train loss: 0.92566 | Train accuracy: 62.67%
Test loss: 3.65538  | Test acc: 12.32%

Epoch: 3
-------
Looked at 0/48928 samples
Looked at 12800/48928 samples
Looked at 25600/48928 samples
Looked at 38400/48928 samples
Train loss: 0.89191 | Train accuracy: 63.84%
Test loss: 3.30463  | Test acc: 11.86%

Epoch: 4
-------
Looked at 0/48928 samples
Looked at 12800/48928 samples
Looked at 25600/48928 samples
Looked at 38400/48928 samples
Train loss: 0.87086 | Train accuracy: 64.21%
Test loss: 3.23491  | Test acc: 11.77%

Epoch: 5
-------
Looked at 0/48928 samples
Looked at 12800/48928 samples
Looked at 25600/48928 samples
Looked at 38400/48928 samples
Train loss: 0.85562 | Train accuracy: 64.83%
Test loss: 3.49557  | Test acc: 12.31%

Epoch: 6
-------
Looked at 0/48928 samples
Looked at 12800/48928 samples
Looked at 25600/48928 samples
Looked at 38400/48928 samples
Train loss: 0.84121 | Train accuracy: 65.45%
Test loss: 3.47232  | Test acc: 11.58%

Epoch: 7
-------
Looked at 0/48928 samples
Looked at 12800/48928 samples
Looked at 25600/48928 samples
Looked at 38400/48928 samples
Train loss: 0.83079 | Train accuracy: 65.67%
Test loss: 3.79158  | Test acc: 12.34%

Epoch: 8
-------
Looked at 0/48928 samples
Looked at 12800/48928 samples
Looked at 25600/48928 samples
Looked at 38400/48928 samples
Train loss: 0.82044 | Train accuracy: 66.09%
Test loss: 4.18851  | Test acc: 11.15%

Epoch: 9
-------
Looked at 0/48928 samples
Looked at 12800/48928 samples
Looked at 25600/48928 samples
Looked at 38400/48928 samples
Train loss: 0.81000 | Train accuracy: 66.47%
Test loss: 3.91698  | Test acc: 11.79%

Epoch: 10
-------
Looked at 0/48928 samples
Looked at 12800/48928 samples
Looked at 25600/48928 samples
Looked at 38400/48928 samples
Train loss: 0.79962 | Train accuracy: 66.75%
Test loss: 4.18682  | Test acc: 12.18%

Epoch: 11
-------
Looked at 0/48928 samples
Looked at 12800/48928 samples
Looked at 25600/48928 samples
Looked at 38400/48928 samples
Train loss: 0.79197 | Train accuracy: 67.13%
Test loss: 4.49825  | Test acc: 12.23%

Epoch: 12
-------
Looked at 0/48928 samples
Looked at 12800/48928 samples
Looked at 25600/48928 samples
Looked at 38400/48928 samples
Train loss: 0.78415 | Train accuracy: 67.35%
Test loss: 4.14071  | Test acc: 12.55%

Epoch: 13
-------
Looked at 0/48928 samples
Looked at 12800/48928 samples
Looked at 25600/48928 samples
Looked at 38400/48928 samples
Train loss: 0.77773 | Train accuracy: 67.48%
Test loss: 4.29729  | Test acc: 11.53%

Epoch: 14
-------
Looked at 0/48928 samples
Looked at 12800/48928 samples
Looked at 25600/48928 samples
Looked at 38400/48928 samples
Train loss: 0.76907 | Train accuracy: 67.91%
Test loss: 4.25597  | Test acc: 11.74%

Epoch: 15
-------
Looked at 0/48928 samples
Looked at 12800/48928 samples
Looked at 25600/48928 samples
Looked at 38400/48928 samples
Train loss: 0.76018 | Train accuracy: 68.10%
Test loss: 4.62178  | Test acc: 12.79%

Epoch: 16
-------
Looked at 0/48928 samples
Looked at 12800/48928 samples
Looked at 25600/48928 samples
Looked at 38400/48928 samples
Train loss: 0.75374 | Train accuracy: 68.54%
Test loss: 4.78136  | Test acc: 12.26%

Epoch: 17
-------
Looked at 0/48928 samples
Looked at 12800/48928 samples
Looked at 25600/48928 samples
Looked at 38400/48928 samples
Train loss: 0.74606 | Train accuracy: 68.73%
Test loss: 4.64554  | Test acc: 12.57%

Epoch: 18
-------
Looked at 0/48928 samples
Looked at 12800/48928 samples
Looked at 25600/48928 samples
Looked at 38400/48928 samples
Train loss: 0.74087 | Train accuracy: 68.93%
Test loss: 4.40107  | Test acc: 12.06%

Epoch: 19
-------
Looked at 0/48928 samples
Looked at 12800/48928 samples
Looked at 25600/48928 samples
Looked at 38400/48928 samples
Train loss: 0.73278 | Train accuracy: 69.20%
Test loss: 4.38029  | Test acc: 12.45%

Epoch: 20
-------
Looked at 0/48928 samples
Looked at 12800/48928 samples
Looked at 25600/48928 samples
Looked at 38400/48928 samples
Train loss: 0.72703 | Train accuracy: 69.30%
Test loss: 4.97359  | Test acc: 12.87%

Epoch: 21
-------
Looked at 0/48928 samples
Looked at 12800/48928 samples
Looked at 25600/48928 samples
Looked at 38400/48928 samples
Train loss: 0.62742 | Train accuracy: 74.90%
Test loss: 4.31506  | Test acc: 21.29%

Epoch: 22
-------
Looked at 0/48928 samples
Looked at 12800/48928 samples
Looked at 25600/48928 samples
Looked at 38400/48928 samples
Train loss: 0.49661 | Train accuracy: 81.05%
Test loss: 4.29733  | Test acc: 20.22%

Epoch: 23
-------
Looked at 0/48928 samples
Looked at 12800/48928 samples
Looked at 25600/48928 samples
Looked at 38400/48928 samples
Train loss: 0.48469 | Train accuracy: 81.24%
Test loss: 4.70926  | Test acc: 19.32%

Epoch: 24
-------
Looked at 0/48928 samples
Looked at 12800/48928 samples
Looked at 25600/48928 samples
Looked at 38400/48928 samples
Train loss: 0.47972 | Train accuracy: 81.44%
Test loss: 4.67828  | Test acc: 19.39%

Epoch: 25
-------
Looked at 0/48928 samples
Looked at 12800/48928 samples
Looked at 25600/48928 samples
Looked at 38400/48928 samples
Train loss: 0.47067 | Train accuracy: 81.68%
Test loss: 4.87433  | Test acc: 17.17%

Epoch: 26
-------
Looked at 0/48928 samples
Looked at 12800/48928 samples
Looked at 25600/48928 samples
Looked at 38400/48928 samples
Train loss: 0.46738 | Train accuracy: 81.67%
Test loss: 4.79333  | Test acc: 20.20%

Epoch: 27
-------
Looked at 0/48928 samples
Looked at 12800/48928 samples
Looked at 25600/48928 samples
Looked at 38400/48928 samples
Train loss: 0.45710 | Train accuracy: 81.97%
Test loss: 5.00609  | Test acc: 17.80%

Epoch: 28
-------
Looked at 0/48928 samples
Looked at 12800/48928 samples
Looked at 25600/48928 samples
Looked at 38400/48928 samples
Train loss: 0.45095 | Train accuracy: 82.30%
Test loss: 5.27185  | Test acc: 19.01%

Epoch: 29
-------
Looked at 0/48928 samples
Looked at 12800/48928 samples
Looked at 25600/48928 samples
Looked at 38400/48928 samples
Train loss: 0.44688 | Train accuracy: 82.39%
Test loss: 5.77782  | Test acc: 17.99%

Epoch: 30
-------
Looked at 0/48928 samples
Looked at 12800/48928 samples
Looked at 25600/48928 samples
Looked at 38400/48928 samples
Train loss: 0.44088 | Train accuracy: 82.61%
Test loss: 5.35512  | Test acc: 19.33%

Epoch: 31
-------
Looked at 0/48928 samples
Looked at 12800/48928 samples
Looked at 25600/48928 samples
Looked at 38400/48928 samples
Train loss: 0.43528 | Train accuracy: 82.71%
Test loss: 5.06859  | Test acc: 18.96%

Epoch: 32
-------
Looked at 0/48928 samples
Looked at 12800/48928 samples
Looked at 25600/48928 samples
Looked at 38400/48928 samples
Train loss: 0.42984 | Train accuracy: 82.88%
Test loss: 5.57277  | Test acc: 19.00%

Epoch: 33
-------
Looked at 0/48928 samples
Looked at 12800/48928 samples
Looked at 25600/48928 samples
Looked at 38400/48928 samples
Train loss: 0.42832 | Train accuracy: 83.09%
Test loss: 6.06562  | Test acc: 19.58%

Epoch: 34
-------
Looked at 0/48928 samples
Looked at 12800/48928 samples
Looked at 25600/48928 samples
Looked at 38400/48928 samples
Train loss: 0.42268 | Train accuracy: 83.15%
Test loss: 6.02559  | Test acc: 17.81%

Epoch: 35
-------
Looked at 0/48928 samples
Looked at 12800/48928 samples
Looked at 25600/48928 samples
Looked at 38400/48928 samples
Train loss: 0.41773 | Train accuracy: 83.41%
Test loss: 5.96504  | Test acc: 17.90%

Epoch: 36
-------
Looked at 0/48928 samples
Looked at 12800/48928 samples
Looked at 25600/48928 samples
Looked at 38400/48928 samples
Train loss: 0.41541 | Train accuracy: 83.43%
Test loss: 5.73376  | Test acc: 20.11%

Epoch: 37
-------
Looked at 0/48928 samples
Looked at 12800/48928 samples
Looked at 25600/48928 samples
Looked at 38400/48928 samples
Train loss: 0.41111 | Train accuracy: 83.57%
Test loss: 6.45719  | Test acc: 19.12%

Epoch: 38
-------
Looked at 0/48928 samples
Looked at 12800/48928 samples
Looked at 25600/48928 samples
Looked at 38400/48928 samples
Train loss: 0.40617 | Train accuracy: 83.75%
Test loss: 5.90404  | Test acc: 18.63%

Epoch: 39
-------
Looked at 0/48928 samples
Looked at 12800/48928 samples
Looked at 25600/48928 samples
Looked at 38400/48928 samples
Train loss: 0.39960 | Train accuracy: 83.99%
Test loss: 6.77219  | Test acc: 19.11%

Epoch: 40
-------
Looked at 0/48928 samples
Looked at 12800/48928 samples
Looked at 25600/48928 samples
Looked at 38400/48928 samples
Train loss: 0.39901 | Train accuracy: 83.96%
Test loss: 6.40603  | Test acc: 19.29%

Epoch: 41
-------
Looked at 0/48928 samples
Looked at 12800/48928 samples
Looked at 25600/48928 samples
Looked at 38400/48928 samples
Train loss: 0.39868 | Train accuracy: 84.07%
Test loss: 6.65296  | Test acc: 17.32%

Epoch: 42
-------
Looked at 0/48928 samples
Looked at 12800/48928 samples
Looked at 25600/48928 samples
Looked at 38400/48928 samples
Train loss: 0.38858 | Train accuracy: 84.36%
Test loss: 6.79853  | Test acc: 19.35%

Epoch: 43
-------
Looked at 0/48928 samples
Looked at 12800/48928 samples
Looked at 25600/48928 samples
Looked at 38400/48928 samples
Train loss: 0.38975 | Train accuracy: 84.36%
Test loss: 7.74652  | Test acc: 18.94%

Epoch: 44
-------
Looked at 0/48928 samples
Looked at 12800/48928 samples
Looked at 25600/48928 samples
Looked at 38400/48928 samples
Train loss: 0.39016 | Train accuracy: 84.28%
Test loss: 6.80164  | Test acc: 19.40%

Epoch: 45
-------
Looked at 0/48928 samples
Looked at 12800/48928 samples
Looked at 25600/48928 samples
Looked at 38400/48928 samples
Train loss: 0.38702 | Train accuracy: 84.49%
Test loss: 6.29122  | Test acc: 19.60%

Epoch: 46
-------
Looked at 0/48928 samples
Looked at 12800/48928 samples
Looked at 25600/48928 samples
Looked at 38400/48928 samples
Train loss: 0.38061 | Train accuracy: 84.64%
Test loss: 6.97362  | Test acc: 17.99%

Epoch: 47
-------
Looked at 0/48928 samples
Looked at 12800/48928 samples
Looked at 25600/48928 samples
Looked at 38400/48928 samples
Train loss: 0.38282 | Train accuracy: 84.56%
Test loss: 6.80595  | Test acc: 18.37%

Epoch: 48
-------
Looked at 0/48928 samples
Looked at 12800/48928 samples
Looked at 25600/48928 samples
Looked at 38400/48928 samples
Train loss: 0.37655 | Train accuracy: 84.76%
Test loss: 6.37659  | Test acc: 18.49%

Epoch: 49
-------
Looked at 0/48928 samples
Looked at 12800/48928 samples
Looked at 25600/48928 samples
Looked at 38400/48928 samples
Train loss: 0.37762 | Train accuracy: 84.74%
Test loss: 6.97492  | Test acc: 18.60%

</code></pre>
</div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:472}"
id="HdPLtQETtHD7" data-outputId="f0f9d334-5d2b-4e12-9538-3bfdbd1165d5">
<div class="sourceCode" id="cb69"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a>plt.plot([loss.item() <span class="cf">for</span> loss <span class="kw">in</span> train_loss_ffnn])</span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Epoch&quot;</span>)</span>
<span id="cb69-3"><a href="#cb69-3" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&quot;Train Loss&quot;</span>)</span>
<span id="cb69-4"><a href="#cb69-4" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&quot;Training Loss Curve&quot;</span>)</span>
<span id="cb69-5"><a href="#cb69-5" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_889211e4574a44c3907c85a1cc095ae7/7289a25017092ec3d697370eca19c9603bed82de.png" /></p>
</div>
</div>
<section id="model-saving" class="cell markdown" id="Qb1pN52BTvru">
<h2>Model Saving</h2>
</section>
<div class="cell code" id="cf7oUEBOrwP4">
<div class="sourceCode" id="cb70"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a><span class="co"># saving the model</span></span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true" tabindex="-1"></a>torch.save(ffnn_model.state_dict(), <span class="st">&#39;ffnn_model.pth&#39;</span>)</span></code></pre></div>
</div>
<section
id="---modelling-and-training-using-convolution-neural-networks-resnet---"
class="cell markdown" id="ISMp33PHQ4GW">
<h1><h1> <b> <center> Modelling and Training using Convolution Neural
Networks (Resnet) </center> </b> </h1></h1>
</section>
<section id="creating-dataloaders" class="cell markdown"
id="IqTDf3LTo1Hy">
<h2>Creating Dataloaders</h2>
</section>
<div class="cell code" id="csNiTZKvo7vu">
<div class="sourceCode" id="cb71"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a>transform <span class="op">=</span> transforms.Compose([transforms.ToTensor()])</span></code></pre></div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="Ys3OXwGVo9x8" data-outputId="44e8a5cb-e6ea-45cb-caca-203126bb68da">
<div class="sourceCode" id="cb72"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a>reduced_train_images_tensor <span class="op">=</span> torch.stack([transform(Image.fromarray(img)) <span class="cf">for</span> img <span class="kw">in</span> train_images])</span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a>reduced_train_labels_tensor <span class="op">=</span> torch.tensor(np.array(reduced_train_labels), dtype<span class="op">=</span>torch.<span class="bu">long</span>)</span>
<span id="cb72-3"><a href="#cb72-3" aria-hidden="true" tabindex="-1"></a>train_dataset <span class="op">=</span> TensorDataset(reduced_train_images_tensor, reduced_train_labels_tensor)</span>
<span id="cb72-4"><a href="#cb72-4" aria-hidden="true" tabindex="-1"></a>train_dataloader <span class="op">=</span> DataLoader(train_dataset, batch_size<span class="op">=</span><span class="dv">32</span>, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb72-5"><a href="#cb72-5" aria-hidden="true" tabindex="-1"></a>train_features_batch, train_labels_batch <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(train_dataloader))</span>
<span id="cb72-6"><a href="#cb72-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-7"><a href="#cb72-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Features Batch Size </span><span class="sc">{</span>train_features_batch<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb72-8"><a href="#cb72-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Labels Batch Size </span><span class="sc">{</span>train_labels_batch<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb72-9"><a href="#cb72-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Length of train dataloader: </span><span class="sc">{</span><span class="bu">len</span>(train_dataloader)<span class="sc">}</span><span class="ss"> batches of 32&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Features Batch Size torch.Size([32, 1, 28, 28])
Labels Batch Size torch.Size([32])
Length of train dataloader: 1579 batches of 32
</code></pre>
</div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="N_xiZP_Lo_Eu" data-outputId="30a553de-5983-4f08-edc3-4f8ecf0d9b20">
<div class="sourceCode" id="cb74"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a>reduced_test_images_tensor <span class="op">=</span> torch.stack([transform(Image.fromarray(img)) <span class="cf">for</span> img <span class="kw">in</span> test_images])</span>
<span id="cb74-2"><a href="#cb74-2" aria-hidden="true" tabindex="-1"></a>reduced_test_labels_tensor <span class="op">=</span> torch.tensor(np.array(test_labels), dtype<span class="op">=</span>torch.<span class="bu">long</span>)</span>
<span id="cb74-3"><a href="#cb74-3" aria-hidden="true" tabindex="-1"></a>test_dataset <span class="op">=</span> TensorDataset(reduced_test_images_tensor, reduced_test_labels_tensor)</span>
<span id="cb74-4"><a href="#cb74-4" aria-hidden="true" tabindex="-1"></a>test_dataloader <span class="op">=</span> DataLoader(test_dataset, batch_size<span class="op">=</span><span class="dv">32</span>, shuffle<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb74-5"><a href="#cb74-5" aria-hidden="true" tabindex="-1"></a>test_features_batch, test_labels_batch <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(test_dataloader))</span>
<span id="cb74-6"><a href="#cb74-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-7"><a href="#cb74-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Features Batch Size </span><span class="sc">{</span>test_features_batch<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb74-8"><a href="#cb74-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Labels Batch Size </span><span class="sc">{</span>test_labels_batch<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb74-9"><a href="#cb74-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Length of train dataloader: </span><span class="sc">{</span><span class="bu">len</span>(test_dataloader)<span class="sc">}</span><span class="ss"> batches of 32&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Features Batch Size torch.Size([32, 1, 28, 28])
Labels Batch Size torch.Size([32])
Length of train dataloader: 313 batches of 32
</code></pre>
</div>
</div>
<section id="creating-model-architecture" class="cell markdown"
id="bhF4c9H-o3Ij">
<h2>Creating Model Architecture</h2>
</section>
<div class="cell code" id="TDZgOgRlqHGY">
<div class="sourceCode" id="cb76"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ResidualBlock2(nn.Module):</span>
<span id="cb76-2"><a href="#cb76-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, in_channels, out_channels, stride <span class="op">=</span> <span class="dv">1</span>):</span>
<span id="cb76-3"><a href="#cb76-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb76-4"><a href="#cb76-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.in_channels <span class="op">=</span> in_channels</span>
<span id="cb76-5"><a href="#cb76-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.out_channels <span class="op">=</span> out_channels</span>
<span id="cb76-6"><a href="#cb76-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-7"><a href="#cb76-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.block <span class="op">=</span> nn.Sequential(</span>
<span id="cb76-8"><a href="#cb76-8" aria-hidden="true" tabindex="-1"></a>                                      nn.Conv2d( in_channels, out_channels, kernel_size<span class="op">=</span><span class="dv">1</span>, stride<span class="op">=</span><span class="dv">1</span>, padding<span class="op">=</span><span class="dv">0</span>, bias<span class="op">=</span><span class="va">False</span>), nn.BatchNorm2d(out_channels), nn.ReLU(),</span>
<span id="cb76-9"><a href="#cb76-9" aria-hidden="true" tabindex="-1"></a>                                      nn.Conv2d( out_channels, out_channels, kernel_size<span class="op">=</span><span class="dv">3</span>, stride<span class="op">=</span>stride, padding<span class="op">=</span><span class="dv">1</span>, bias<span class="op">=</span><span class="va">False</span>), nn.BatchNorm2d(out_channels), nn.ReLU(),</span>
<span id="cb76-10"><a href="#cb76-10" aria-hidden="true" tabindex="-1"></a>                                      nn.Conv2d( out_channels, out_channels <span class="op">*</span> <span class="dv">4</span>, kernel_size<span class="op">=</span><span class="dv">1</span>, stride<span class="op">=</span><span class="dv">1</span>, padding<span class="op">=</span><span class="dv">0</span>, bias<span class="op">=</span><span class="va">False</span>), nn.BatchNorm2d(out_channels <span class="op">*</span> <span class="dv">4</span>)</span>
<span id="cb76-11"><a href="#cb76-11" aria-hidden="true" tabindex="-1"></a>                                  )</span>
<span id="cb76-12"><a href="#cb76-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-13"><a href="#cb76-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dim_matching_layer <span class="op">=</span> nn.Sequential(</span>
<span id="cb76-14"><a href="#cb76-14" aria-hidden="true" tabindex="-1"></a>                            nn.Conv2d(in_channels, out_channels<span class="op">*</span><span class="dv">4</span>, kernel_size <span class="op">=</span> <span class="dv">1</span>, stride <span class="op">=</span> stride, bias <span class="op">=</span> <span class="va">False</span>),</span>
<span id="cb76-15"><a href="#cb76-15" aria-hidden="true" tabindex="-1"></a>                            nn.BatchNorm2d(out_channels<span class="op">*</span><span class="dv">4</span>)</span>
<span id="cb76-16"><a href="#cb76-16" aria-hidden="true" tabindex="-1"></a>                            )</span>
<span id="cb76-17"><a href="#cb76-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-18"><a href="#cb76-18" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb76-19"><a href="#cb76-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-20"><a href="#cb76-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.in_channels <span class="op">!=</span> <span class="dv">4</span> <span class="op">*</span> <span class="va">self</span>.out_channels:</span>
<span id="cb76-21"><a href="#cb76-21" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="va">self</span>.block(x) <span class="op">+</span> <span class="va">self</span>.dim_matching_layer(x)</span>
<span id="cb76-22"><a href="#cb76-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-23"><a href="#cb76-23" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.block(x) <span class="op">+</span> x</span></code></pre></div>
</div>
<div class="cell code" id="E-61DVyzZBRk">
<div class="sourceCode" id="cb77"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ResNet(nn.Module):</span>
<span id="cb77-2"><a href="#cb77-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-3"><a href="#cb77-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb77-4"><a href="#cb77-4" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(ResNet, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb77-5"><a href="#cb77-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-6"><a href="#cb77-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv1 <span class="op">=</span> nn.Sequential( nn.Conv2d(<span class="dv">1</span>, <span class="dv">64</span>, kernel_size<span class="op">=</span><span class="dv">7</span>, stride<span class="op">=</span><span class="dv">2</span>, padding<span class="op">=</span><span class="dv">3</span>, bias<span class="op">=</span><span class="va">False</span>), nn.BatchNorm2d(<span class="dv">64</span>), nn.ReLU() )</span>
<span id="cb77-7"><a href="#cb77-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.maxpool <span class="op">=</span> nn.MaxPool2d(kernel_size<span class="op">=</span><span class="dv">3</span>, stride<span class="op">=</span><span class="dv">2</span>, padding<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb77-8"><a href="#cb77-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-9"><a href="#cb77-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.layer1 <span class="op">=</span> nn.Sequential(</span>
<span id="cb77-10"><a href="#cb77-10" aria-hidden="true" tabindex="-1"></a>                                        ResidualBlock2(<span class="dv">64</span>, <span class="dv">64</span>, <span class="dv">1</span>),</span>
<span id="cb77-11"><a href="#cb77-11" aria-hidden="true" tabindex="-1"></a>                                        ResidualBlock2(<span class="dv">256</span>, <span class="dv">64</span>),</span>
<span id="cb77-12"><a href="#cb77-12" aria-hidden="true" tabindex="-1"></a>                                        <span class="co"># ResidualBlock2(256, 64)</span></span>
<span id="cb77-13"><a href="#cb77-13" aria-hidden="true" tabindex="-1"></a>                                    )</span>
<span id="cb77-14"><a href="#cb77-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-15"><a href="#cb77-15" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.layer2 <span class="op">=</span> nn.Sequential(</span>
<span id="cb77-16"><a href="#cb77-16" aria-hidden="true" tabindex="-1"></a>                                        ResidualBlock2(<span class="dv">256</span>, <span class="dv">128</span>, <span class="dv">2</span>),</span>
<span id="cb77-17"><a href="#cb77-17" aria-hidden="true" tabindex="-1"></a>                                        ResidualBlock2(<span class="dv">512</span>, <span class="dv">128</span>),</span>
<span id="cb77-18"><a href="#cb77-18" aria-hidden="true" tabindex="-1"></a>                                        <span class="co"># ResidualBlock2(512, 128), #1</span></span>
<span id="cb77-19"><a href="#cb77-19" aria-hidden="true" tabindex="-1"></a>                                        <span class="co"># ResidualBlock2(512, 128), #2</span></span>
<span id="cb77-20"><a href="#cb77-20" aria-hidden="true" tabindex="-1"></a>                                        <span class="co"># ResidualBlock2(512, 128), #3</span></span>
<span id="cb77-21"><a href="#cb77-21" aria-hidden="true" tabindex="-1"></a>                                        <span class="co"># ResidualBlock2(512, 128), #4</span></span>
<span id="cb77-22"><a href="#cb77-22" aria-hidden="true" tabindex="-1"></a>                                        <span class="co"># ResidualBlock2(512, 128), #5</span></span>
<span id="cb77-23"><a href="#cb77-23" aria-hidden="true" tabindex="-1"></a>                                        ResidualBlock2(<span class="dv">512</span>, <span class="dv">128</span>)  <span class="co">#6</span></span>
<span id="cb77-24"><a href="#cb77-24" aria-hidden="true" tabindex="-1"></a>                                    )</span>
<span id="cb77-25"><a href="#cb77-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-26"><a href="#cb77-26" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.layer3 <span class="op">=</span> nn.Sequential(</span>
<span id="cb77-27"><a href="#cb77-27" aria-hidden="true" tabindex="-1"></a>                                        ResidualBlock2(<span class="dv">512</span>, <span class="dv">256</span>, <span class="dv">2</span>),</span>
<span id="cb77-28"><a href="#cb77-28" aria-hidden="true" tabindex="-1"></a>                                        ResidualBlock2(<span class="dv">1024</span>, <span class="dv">256</span>),</span>
<span id="cb77-29"><a href="#cb77-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-30"><a href="#cb77-30" aria-hidden="true" tabindex="-1"></a>                                        ResidualBlock2(<span class="dv">1024</span>, <span class="dv">256</span>), <span class="co">#1</span></span>
<span id="cb77-31"><a href="#cb77-31" aria-hidden="true" tabindex="-1"></a>                                        <span class="co"># ResidualBlock2(1024, 256), #2</span></span>
<span id="cb77-32"><a href="#cb77-32" aria-hidden="true" tabindex="-1"></a>                                        <span class="co"># ResidualBlock2(1024, 256), #3</span></span>
<span id="cb77-33"><a href="#cb77-33" aria-hidden="true" tabindex="-1"></a>                                        <span class="co"># ResidualBlock2(1024, 256), #4</span></span>
<span id="cb77-34"><a href="#cb77-34" aria-hidden="true" tabindex="-1"></a>                                        <span class="co"># ResidualBlock2(1024, 256), #5</span></span>
<span id="cb77-35"><a href="#cb77-35" aria-hidden="true" tabindex="-1"></a>                                        <span class="co"># ResidualBlock2(1024, 256), #6</span></span>
<span id="cb77-36"><a href="#cb77-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-37"><a href="#cb77-37" aria-hidden="true" tabindex="-1"></a>                                        ResidualBlock2(<span class="dv">1024</span>, <span class="dv">256</span>), <span class="co">#7</span></span>
<span id="cb77-38"><a href="#cb77-38" aria-hidden="true" tabindex="-1"></a>                                        <span class="co"># ResidualBlock2(1024, 256), #8</span></span>
<span id="cb77-39"><a href="#cb77-39" aria-hidden="true" tabindex="-1"></a>                                        <span class="co"># ResidualBlock2(1024, 256), #9</span></span>
<span id="cb77-40"><a href="#cb77-40" aria-hidden="true" tabindex="-1"></a>                                        <span class="co"># ResidualBlock2(1024, 256), #10</span></span>
<span id="cb77-41"><a href="#cb77-41" aria-hidden="true" tabindex="-1"></a>                                        <span class="co"># ResidualBlock2(1024, 256), #11</span></span>
<span id="cb77-42"><a href="#cb77-42" aria-hidden="true" tabindex="-1"></a>                                        <span class="co"># ResidualBlock2(1024, 256), #12</span></span>
<span id="cb77-43"><a href="#cb77-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-44"><a href="#cb77-44" aria-hidden="true" tabindex="-1"></a>                                        ResidualBlock2(<span class="dv">1024</span>, <span class="dv">256</span>), <span class="co">#13</span></span>
<span id="cb77-45"><a href="#cb77-45" aria-hidden="true" tabindex="-1"></a>                                        <span class="co"># ResidualBlock2(1024, 256), #14</span></span>
<span id="cb77-46"><a href="#cb77-46" aria-hidden="true" tabindex="-1"></a>                                        <span class="co"># ResidualBlock2(1024, 256), #15</span></span>
<span id="cb77-47"><a href="#cb77-47" aria-hidden="true" tabindex="-1"></a>                                        <span class="co"># ResidualBlock2(1024, 256), #16</span></span>
<span id="cb77-48"><a href="#cb77-48" aria-hidden="true" tabindex="-1"></a>                                        <span class="co"># ResidualBlock2(1024, 256), #17</span></span>
<span id="cb77-49"><a href="#cb77-49" aria-hidden="true" tabindex="-1"></a>                                        <span class="co"># ResidualBlock2(1024, 256), #18</span></span>
<span id="cb77-50"><a href="#cb77-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-51"><a href="#cb77-51" aria-hidden="true" tabindex="-1"></a>                                        ResidualBlock2(<span class="dv">1024</span>, <span class="dv">256</span>), <span class="co">#19</span></span>
<span id="cb77-52"><a href="#cb77-52" aria-hidden="true" tabindex="-1"></a>                                        <span class="co"># ResidualBlock2(1024, 256), #20</span></span>
<span id="cb77-53"><a href="#cb77-53" aria-hidden="true" tabindex="-1"></a>                                        <span class="co"># ResidualBlock2(1024, 256), #21</span></span>
<span id="cb77-54"><a href="#cb77-54" aria-hidden="true" tabindex="-1"></a>                                        <span class="co"># ResidualBlock2(1024, 256), #22</span></span>
<span id="cb77-55"><a href="#cb77-55" aria-hidden="true" tabindex="-1"></a>                                        <span class="co"># ResidualBlock2(1024, 256), #23</span></span>
<span id="cb77-56"><a href="#cb77-56" aria-hidden="true" tabindex="-1"></a>                                        <span class="co"># ResidualBlock2(1024, 256), #24</span></span>
<span id="cb77-57"><a href="#cb77-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-58"><a href="#cb77-58" aria-hidden="true" tabindex="-1"></a>                                        ResidualBlock2(<span class="dv">1024</span>, <span class="dv">256</span>), <span class="co">#25</span></span>
<span id="cb77-59"><a href="#cb77-59" aria-hidden="true" tabindex="-1"></a>                                        <span class="co"># ResidualBlock2(1024, 256), #26</span></span>
<span id="cb77-60"><a href="#cb77-60" aria-hidden="true" tabindex="-1"></a>                                        <span class="co"># ResidualBlock2(1024, 256), #27</span></span>
<span id="cb77-61"><a href="#cb77-61" aria-hidden="true" tabindex="-1"></a>                                        <span class="co"># ResidualBlock2(1024, 256), #28</span></span>
<span id="cb77-62"><a href="#cb77-62" aria-hidden="true" tabindex="-1"></a>                                        <span class="co"># ResidualBlock2(1024, 256), #29</span></span>
<span id="cb77-63"><a href="#cb77-63" aria-hidden="true" tabindex="-1"></a>                                        <span class="co"># ResidualBlock2(1024, 256), #30</span></span>
<span id="cb77-64"><a href="#cb77-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-65"><a href="#cb77-65" aria-hidden="true" tabindex="-1"></a>                                        <span class="co"># ResidualBlock2(1024, 256), #31</span></span>
<span id="cb77-66"><a href="#cb77-66" aria-hidden="true" tabindex="-1"></a>                                        <span class="co"># ResidualBlock2(1024, 256), #32</span></span>
<span id="cb77-67"><a href="#cb77-67" aria-hidden="true" tabindex="-1"></a>                                        <span class="co"># ResidualBlock2(1024, 256), #33</span></span>
<span id="cb77-68"><a href="#cb77-68" aria-hidden="true" tabindex="-1"></a>                                        ResidualBlock2(<span class="dv">1024</span>, <span class="dv">256</span>), <span class="co">#34</span></span>
<span id="cb77-69"><a href="#cb77-69" aria-hidden="true" tabindex="-1"></a>                                    )</span>
<span id="cb77-70"><a href="#cb77-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-71"><a href="#cb77-71" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.layer4 <span class="op">=</span> nn.Sequential(</span>
<span id="cb77-72"><a href="#cb77-72" aria-hidden="true" tabindex="-1"></a>                                        ResidualBlock2(<span class="dv">1024</span>, <span class="dv">512</span>, <span class="dv">2</span>),</span>
<span id="cb77-73"><a href="#cb77-73" aria-hidden="true" tabindex="-1"></a>                                        ResidualBlock2(<span class="dv">2048</span>, <span class="dv">512</span>),</span>
<span id="cb77-74"><a href="#cb77-74" aria-hidden="true" tabindex="-1"></a>                                        ResidualBlock2(<span class="dv">2048</span>, <span class="dv">512</span>),</span>
<span id="cb77-75"><a href="#cb77-75" aria-hidden="true" tabindex="-1"></a>                                    )</span>
<span id="cb77-76"><a href="#cb77-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-77"><a href="#cb77-77" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.avgpool <span class="op">=</span> nn.AdaptiveAvgPool2d((<span class="dv">1</span>, <span class="dv">1</span>))</span>
<span id="cb77-78"><a href="#cb77-78" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc <span class="op">=</span> nn.Linear(<span class="dv">2048</span>, <span class="dv">10</span>)</span>
<span id="cb77-79"><a href="#cb77-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-80"><a href="#cb77-80" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb77-81"><a href="#cb77-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-82"><a href="#cb77-82" aria-hidden="true" tabindex="-1"></a>        <span class="co"># feature extraction</span></span>
<span id="cb77-83"><a href="#cb77-83" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.conv1(x)</span>
<span id="cb77-84"><a href="#cb77-84" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.maxpool(x)</span>
<span id="cb77-85"><a href="#cb77-85" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.layer1(x)</span>
<span id="cb77-86"><a href="#cb77-86" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.layer2(x)</span>
<span id="cb77-87"><a href="#cb77-87" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.layer3(x)</span>
<span id="cb77-88"><a href="#cb77-88" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.layer4(x)</span>
<span id="cb77-89"><a href="#cb77-89" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.avgpool(x)</span>
<span id="cb77-90"><a href="#cb77-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-91"><a href="#cb77-91" aria-hidden="true" tabindex="-1"></a>        <span class="co"># image flattening</span></span>
<span id="cb77-92"><a href="#cb77-92" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> x.reshape(x.shape[<span class="dv">0</span>], <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb77-93"><a href="#cb77-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-94"><a href="#cb77-94" aria-hidden="true" tabindex="-1"></a>        <span class="co"># classification</span></span>
<span id="cb77-95"><a href="#cb77-95" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.fc(x)</span>
<span id="cb77-96"><a href="#cb77-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-97"><a href="#cb77-97" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span></code></pre></div>
</div>
<div class="cell code" id="Qenw46FMqFDf">
<div class="sourceCode" id="cb78"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a><span class="co"># instantiating the model</span></span>
<span id="cb78-2"><a href="#cb78-2" aria-hidden="true" tabindex="-1"></a>resnet_model <span class="op">=</span> ResNet().to(device)</span></code></pre></div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:1000,&quot;referenced_widgets&quot;:[&quot;de0c8c4320ae4634ae51b98a93a54366&quot;,&quot;9caf4e40bc1d424582de5931973e5387&quot;,&quot;79e611af64dd4f1e8177a03763aeba14&quot;,&quot;80b23ca96ffa420286c0acb375a11474&quot;,&quot;df5bf40526ef48899578f8cfa0d0669e&quot;,&quot;20d2169f69f14759a2366da7ee9373db&quot;,&quot;21f27f33f43648bb823597990aee3b50&quot;,&quot;882f92457d42492abd7bd57c7eb6a34d&quot;,&quot;e8378362a8f04956b4cd95a832bb5221&quot;,&quot;e6260728b19d43b5bdcb4ee41f855372&quot;,&quot;87c46640fd0d477fa5d96e6bb0f3964a&quot;]}"
id="PdkRyH_7uUBE" data-outputId="4c774831-2909-4561-c012-1072e8a16ec3">
<div class="sourceCode" id="cb79"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a>train_loss_res, train_acc_res, test_loss_ffnn, test_acc_res <span class="op">=</span> train_step(resnet_model, train_dataloader, <span class="st">&#39;SGD&#39;</span>)</span></code></pre></div>
<div class="output display_data">
<div class="sourceCode" id="cb80"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;de0c8c4320ae4634ae51b98a93a54366&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stdout">
<pre><code>Epoch: 0
-------
Looked at 0/50503 samples
Looked at 12800/50503 samples
Looked at 25600/50503 samples
Looked at 38400/50503 samples
Train loss: 1.60686 | Train accuracy: 67.70%
Test loss: 4.16107  | Test acc: 71.76%

Epoch: 1
-------
Looked at 0/50503 samples
Looked at 12800/50503 samples
Looked at 25600/50503 samples
Looked at 38400/50503 samples
Train loss: 0.58043 | Train accuracy: 79.54%
Test loss: 0.51627  | Test acc: 80.64%

Epoch: 2
-------
Looked at 0/50503 samples
Looked at 12800/50503 samples
Looked at 25600/50503 samples
Looked at 38400/50503 samples
Train loss: 0.43881 | Train accuracy: 83.96%
Test loss: 0.41057  | Test acc: 84.98%

Epoch: 3
-------
Looked at 0/50503 samples
Looked at 12800/50503 samples
Looked at 25600/50503 samples
Looked at 38400/50503 samples
Train loss: 0.38454 | Train accuracy: 85.72%
Test loss: 0.64745  | Test acc: 81.42%

Epoch: 4
-------
Looked at 0/50503 samples
Looked at 12800/50503 samples
Looked at 25600/50503 samples
Looked at 38400/50503 samples
Train loss: 0.35431 | Train accuracy: 87.01%
Test loss: 0.68935  | Test acc: 76.08%

Epoch: 5
-------
Looked at 0/50503 samples
Looked at 12800/50503 samples
Looked at 25600/50503 samples
Looked at 38400/50503 samples
Train loss: 0.32724 | Train accuracy: 87.85%
Test loss: 0.32813  | Test acc: 88.02%

Epoch: 6
-------
Looked at 0/50503 samples
Looked at 12800/50503 samples
Looked at 25600/50503 samples
Looked at 38400/50503 samples
Train loss: 0.30885 | Train accuracy: 88.41%
Test loss: 0.34571  | Test acc: 87.40%

Epoch: 7
-------
Looked at 0/50503 samples
Looked at 12800/50503 samples
Looked at 25600/50503 samples
Looked at 38400/50503 samples
Train loss: 0.29181 | Train accuracy: 89.29%
Test loss: 0.32165  | Test acc: 88.79%

Epoch: 8
-------
Looked at 0/50503 samples
Looked at 12800/50503 samples
Looked at 25600/50503 samples
Looked at 38400/50503 samples
Train loss: 0.27771 | Train accuracy: 89.51%
Test loss: 0.37526  | Test acc: 86.69%

Epoch: 9
-------
Looked at 0/50503 samples
Looked at 12800/50503 samples
Looked at 25600/50503 samples
Looked at 38400/50503 samples
Train loss: 0.26371 | Train accuracy: 90.04%
Test loss: 0.64780  | Test acc: 80.99%

Epoch: 10
-------
Looked at 0/50503 samples
Looked at 12800/50503 samples
Looked at 25600/50503 samples
Looked at 38400/50503 samples
Train loss: 0.25161 | Train accuracy: 90.58%
Test loss: 0.32214  | Test acc: 88.79%

Epoch: 11
-------
Looked at 0/50503 samples
Looked at 12800/50503 samples
Looked at 25600/50503 samples
Looked at 38400/50503 samples
Train loss: 0.23594 | Train accuracy: 90.97%
Test loss: 0.38407  | Test acc: 86.29%

Epoch: 12
-------
Looked at 0/50503 samples
Looked at 12800/50503 samples
Looked at 25600/50503 samples
Looked at 38400/50503 samples
Train loss: 0.22532 | Train accuracy: 91.50%
Test loss: 0.44629  | Test acc: 85.61%

Epoch: 13
-------
Looked at 0/50503 samples
Looked at 12800/50503 samples
Looked at 25600/50503 samples
Looked at 38400/50503 samples
Train loss: 0.22274 | Train accuracy: 91.49%
Test loss: 2.74840  | Test acc: 78.34%

Epoch: 14
-------
Looked at 0/50503 samples
Looked at 12800/50503 samples
Looked at 25600/50503 samples
Looked at 38400/50503 samples
Train loss: 0.20768 | Train accuracy: 92.20%
Test loss: 0.50382  | Test acc: 86.50%

Epoch: 15
-------
Looked at 0/50503 samples
Looked at 12800/50503 samples
Looked at 25600/50503 samples
Looked at 38400/50503 samples
Train loss: 0.19793 | Train accuracy: 92.54%
Test loss: 0.45672  | Test acc: 86.87%

Epoch: 16
-------
Looked at 0/50503 samples
Looked at 12800/50503 samples
Looked at 25600/50503 samples
Looked at 38400/50503 samples
Train loss: 0.18853 | Train accuracy: 92.85%
Test loss: 0.37498  | Test acc: 87.48%

Epoch: 17
-------
Looked at 0/50503 samples
Looked at 12800/50503 samples
Looked at 25600/50503 samples
Looked at 38400/50503 samples
Train loss: 0.18287 | Train accuracy: 93.01%
Test loss: 0.32233  | Test acc: 89.19%

Epoch: 18
-------
Looked at 0/50503 samples
Looked at 12800/50503 samples
Looked at 25600/50503 samples
Looked at 38400/50503 samples
Train loss: 0.17033 | Train accuracy: 93.54%
Test loss: 0.43551  | Test acc: 85.86%

Epoch: 19
-------
Looked at 0/50503 samples
Looked at 12800/50503 samples
Looked at 25600/50503 samples
Looked at 38400/50503 samples
Train loss: 0.16360 | Train accuracy: 93.70%
Test loss: 1.47836  | Test acc: 82.54%

Epoch: 20
-------
Looked at 0/50503 samples
Looked at 12800/50503 samples
Looked at 25600/50503 samples
Looked at 38400/50503 samples
Train loss: 0.15489 | Train accuracy: 94.18%
Test loss: 0.33300  | Test acc: 89.43%

Epoch: 21
-------
Looked at 0/50503 samples
Looked at 12800/50503 samples
Looked at 25600/50503 samples
Looked at 38400/50503 samples
Train loss: 0.14849 | Train accuracy: 94.46%
Test loss: 0.40460  | Test acc: 88.11%

Epoch: 22
-------
Looked at 0/50503 samples
Looked at 12800/50503 samples
Looked at 25600/50503 samples
Looked at 38400/50503 samples
Train loss: 0.13807 | Train accuracy: 94.70%
Test loss: 0.36339  | Test acc: 88.64%

Epoch: 23
-------
Looked at 0/50503 samples
Looked at 12800/50503 samples
Looked at 25600/50503 samples
Looked at 38400/50503 samples
Train loss: 0.13178 | Train accuracy: 95.02%
Test loss: 0.49603  | Test acc: 86.98%

Epoch: 24
-------
Looked at 0/50503 samples
Looked at 12800/50503 samples
Looked at 25600/50503 samples
Looked at 38400/50503 samples
Train loss: 0.12601 | Train accuracy: 95.22%
Test loss: 0.33806  | Test acc: 89.18%

Epoch: 25
-------
Looked at 0/50503 samples
Looked at 12800/50503 samples
Looked at 25600/50503 samples
Looked at 38400/50503 samples
Train loss: 0.11529 | Train accuracy: 95.64%
Test loss: 0.61742  | Test acc: 84.44%

Epoch: 26
-------
Looked at 0/50503 samples
Looked at 12800/50503 samples
Looked at 25600/50503 samples
Looked at 38400/50503 samples
Train loss: 0.11469 | Train accuracy: 95.65%
Test loss: 0.36817  | Test acc: 88.48%

Epoch: 27
-------
Looked at 0/50503 samples
Looked at 12800/50503 samples
Looked at 25600/50503 samples
Looked at 38400/50503 samples
Train loss: 0.10416 | Train accuracy: 96.10%
Test loss: 0.53190  | Test acc: 85.42%

Epoch: 28
-------
Looked at 0/50503 samples
Looked at 12800/50503 samples
Looked at 25600/50503 samples
Looked at 38400/50503 samples
Train loss: 0.09918 | Train accuracy: 96.23%
Test loss: 0.45728  | Test acc: 87.04%

Epoch: 29
-------
Looked at 0/50503 samples
Looked at 12800/50503 samples
Looked at 25600/50503 samples
Looked at 38400/50503 samples
Train loss: 0.09466 | Train accuracy: 96.34%
Test loss: 0.37598  | Test acc: 89.74%

Epoch: 30
-------
Looked at 0/50503 samples
Looked at 12800/50503 samples
Looked at 25600/50503 samples
Looked at 38400/50503 samples
Train loss: 0.09061 | Train accuracy: 96.55%
Test loss: 0.41429  | Test acc: 89.89%

Epoch: 31
-------
Looked at 0/50503 samples
Looked at 12800/50503 samples
Looked at 25600/50503 samples
Looked at 38400/50503 samples
Train loss: 0.08691 | Train accuracy: 96.75%
Test loss: 0.45500  | Test acc: 89.10%

Epoch: 32
-------
Looked at 0/50503 samples
Looked at 12800/50503 samples
Looked at 25600/50503 samples
Looked at 38400/50503 samples
Train loss: 0.07796 | Train accuracy: 97.11%
Test loss: 0.71539  | Test acc: 83.74%

Epoch: 33
-------
Looked at 0/50503 samples
Looked at 12800/50503 samples
Looked at 25600/50503 samples
Looked at 38400/50503 samples
Train loss: 0.07570 | Train accuracy: 97.14%
Test loss: 1.04984  | Test acc: 80.12%

Epoch: 34
-------
Looked at 0/50503 samples
Looked at 12800/50503 samples
Looked at 25600/50503 samples
Looked at 38400/50503 samples
</code></pre>
</div>
</div>
<div class="cell code" id="lGlMRhOfvZmL">
<div class="sourceCode" id="cb82"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a>plt.plot([loss.item() <span class="cf">for</span> loss <span class="kw">in</span> train_loss_res])</span>
<span id="cb82-2"><a href="#cb82-2" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Epoch&quot;</span>)</span>
<span id="cb82-3"><a href="#cb82-3" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&quot;Train Loss&quot;</span>)</span>
<span id="cb82-4"><a href="#cb82-4" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&quot;Training Loss Curve&quot;</span>)</span>
<span id="cb82-5"><a href="#cb82-5" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
</div>
<div class="cell code" id="4Yu6PDuIvaIs">
<div class="sourceCode" id="cb83"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a><span class="co"># saving the model</span></span>
<span id="cb83-2"><a href="#cb83-2" aria-hidden="true" tabindex="-1"></a>torch.save(resnet_model.state_dict(), <span class="st">&#39;resnet_model.pth&#39;</span>)</span></code></pre></div>
</div>
<section id="---modelling-and-training-using-vision-transformers---"
class="cell markdown" id="sCf-ekwJQ4GW">
<h1><h1> <b> <center> Modelling and Training using Vision Transformers
</center> </b> </h1></h1>
</section>
<div class="cell code" id="rhH46PjsZC-i">
<div class="sourceCode" id="cb84"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ViT(nn.Module):</span>
<span id="cb84-2"><a href="#cb84-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-3"><a href="#cb84-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, img_size:<span class="bu">int</span><span class="op">=</span><span class="dv">28</span>, in_channels:<span class="bu">int</span><span class="op">=</span><span class="dv">1</span>, patch_size:<span class="bu">int</span><span class="op">=</span><span class="dv">4</span>, embedding_dim:<span class="bu">int</span><span class="op">=</span><span class="dv">768</span>, mlp_size:<span class="bu">int</span><span class="op">=</span><span class="dv">3072</span>, num_classes:<span class="bu">int</span><span class="op">=</span><span class="dv">1000</span>):</span>
<span id="cb84-4"><a href="#cb84-4" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb84-5"><a href="#cb84-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-6"><a href="#cb84-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.patch_embedding <span class="op">=</span> nn.Sequential(nn.LayerNorm(<span class="dv">1</span><span class="op">*</span><span class="dv">4</span><span class="op">*</span><span class="dv">4</span>), nn.Linear(<span class="dv">1</span><span class="op">*</span><span class="dv">4</span><span class="op">*</span><span class="dv">4</span>, <span class="dv">768</span>), nn.LayerNorm(<span class="dv">768</span>))</span>
<span id="cb84-7"><a href="#cb84-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-8"><a href="#cb84-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.class_embedding <span class="op">=</span> nn.Parameter(data<span class="op">=</span>torch.randn(<span class="dv">1</span>, <span class="dv">1</span>, embedding_dim), requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb84-9"><a href="#cb84-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-10"><a href="#cb84-10" aria-hidden="true" tabindex="-1"></a>        num_patches <span class="op">=</span> (img_size <span class="op">//</span> patch_size) <span class="op">*</span> (img_size <span class="op">//</span> patch_size)</span>
<span id="cb84-11"><a href="#cb84-11" aria-hidden="true" tabindex="-1"></a>        <span class="co"># num_patches = (img_size * img_size) // patch_size**2</span></span>
<span id="cb84-12"><a href="#cb84-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.position_embedding <span class="op">=</span> nn.Parameter(data<span class="op">=</span>torch.randn(<span class="dv">1</span>, num_patches<span class="op">+</span><span class="dv">1</span>, embedding_dim),requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb84-13"><a href="#cb84-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.embedding_dropout <span class="op">=</span> nn.Dropout(p<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb84-14"><a href="#cb84-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-15"><a href="#cb84-15" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.transformer_encoder <span class="op">=</span> nn.TransformerEncoder(encoder_layer<span class="op">=</span>nn.TransformerEncoderLayer(d_model<span class="op">=</span>embedding_dim,</span>
<span id="cb84-16"><a href="#cb84-16" aria-hidden="true" tabindex="-1"></a>                                                                                                  nhead<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb84-17"><a href="#cb84-17" aria-hidden="true" tabindex="-1"></a>                                                                                                  dim_feedforward<span class="op">=</span>mlp_size,</span>
<span id="cb84-18"><a href="#cb84-18" aria-hidden="true" tabindex="-1"></a>                                                                                                  activation<span class="op">=</span><span class="st">&quot;gelu&quot;</span>,</span>
<span id="cb84-19"><a href="#cb84-19" aria-hidden="true" tabindex="-1"></a>                                                                                                  batch_first<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb84-20"><a href="#cb84-20" aria-hidden="true" tabindex="-1"></a>                                                                                                  norm_first<span class="op">=</span><span class="va">True</span>), <span class="co"># Create a single Transformer Encoder Layer</span></span>
<span id="cb84-21"><a href="#cb84-21" aria-hidden="true" tabindex="-1"></a>                                                        num_layers<span class="op">=</span><span class="dv">2</span>) <span class="co"># Stack it N times</span></span>
<span id="cb84-22"><a href="#cb84-22" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.classifier <span class="op">=</span> nn.Sequential( nn.LayerNorm(normalized_shape<span class="op">=</span>embedding_dim), nn.Linear(in_features<span class="op">=</span>embedding_dim, out_features<span class="op">=</span>num_classes))</span>
<span id="cb84-23"><a href="#cb84-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-24"><a href="#cb84-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-25"><a href="#cb84-25" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb84-26"><a href="#cb84-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-27"><a href="#cb84-27" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 32, 1, 28, 28 -&gt; 32, 1, 7*4, 7*4 -&gt; 32, 1, 7, 7, 4, 4 -&gt; 32, 7, 7, 4, 4, 1 -&gt; 32, 7*7, 4*4*1 - &gt; 32, num_patches, patch_dim</span></span>
<span id="cb84-28"><a href="#cb84-28" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> rearrange(x, <span class="st">&#39;b c (nh ph) (nw pw) -&gt; b (nh nw) (ph pw c)&#39;</span>, ph<span class="op">=</span><span class="dv">4</span>, pw<span class="op">=</span><span class="dv">4</span>)</span>
<span id="cb84-29"><a href="#cb84-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-30"><a href="#cb84-30" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Create patch embedding for all images in the batch</span></span>
<span id="cb84-31"><a href="#cb84-31" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.patch_embedding(x)</span>
<span id="cb84-32"><a href="#cb84-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-33"><a href="#cb84-33" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Create class embedding and expand it to match the batch size.</span></span>
<span id="cb84-34"><a href="#cb84-34" aria-hidden="true" tabindex="-1"></a>        class_token <span class="op">=</span> <span class="va">self</span>.class_embedding.expand(x.shape[<span class="dv">0</span>], <span class="op">-</span><span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>) <span class="co"># &quot;-1&quot; means to infer the dimension (try this line on its own)</span></span>
<span id="cb84-35"><a href="#cb84-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-36"><a href="#cb84-36" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Concat class embedding with the patch embedding</span></span>
<span id="cb84-37"><a href="#cb84-37" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> torch.cat((class_token, x), dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb84-38"><a href="#cb84-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-39"><a href="#cb84-39" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 16. Add position embedding to patch embedding</span></span>
<span id="cb84-40"><a href="#cb84-40" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.position_embedding <span class="op">+</span> x</span>
<span id="cb84-41"><a href="#cb84-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-42"><a href="#cb84-42" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 17. Run embedding dropout</span></span>
<span id="cb84-43"><a href="#cb84-43" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.embedding_dropout(x)</span>
<span id="cb84-44"><a href="#cb84-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-45"><a href="#cb84-45" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 18. Pass patch, position and class embedding through transformer encoder layers (equations 2 &amp; 3)</span></span>
<span id="cb84-46"><a href="#cb84-46" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.transformer_encoder(x)</span>
<span id="cb84-47"><a href="#cb84-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-48"><a href="#cb84-48" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 19. Put 0 index logit through classifier (equation 4)</span></span>
<span id="cb84-49"><a href="#cb84-49" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.classifier(x[:, <span class="dv">0</span>]) <span class="co"># run on each sample in a batch at 0 index</span></span>
<span id="cb84-50"><a href="#cb84-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-51"><a href="#cb84-51" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span></code></pre></div>
</div>
<div class="cell code" id="0YvSrRAswe0i">
<div class="sourceCode" id="cb85"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> ViT(num_classes<span class="op">=</span><span class="dv">10</span>).to(device)</span></code></pre></div>
</div>
<section id="---result-analysis-and-conclusions---"
class="cell markdown" id="tPIhOMH8r0oD">
<h1><h1> <b> <center> Result Analysis and Conclusions </center> </b>
</h1></h1>
<ul>
<li>Show prediction and actual + show comparision between models</li>
<li>performance on test data</li>
<li>test data accuracy</li>
</ul>
</section>
<div class="cell code" id="3TlHY0Asr1j9">
<div class="sourceCode" id="cb86"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a><span class="co"># To load the model later:</span></span>
<span id="cb86-2"><a href="#cb86-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> FFNN_Model() <span class="co"># Instantiate the model architecture</span></span>
<span id="cb86-3"><a href="#cb86-3" aria-hidden="true" tabindex="-1"></a>model.load_state_dict(torch.load(<span class="st">&#39;ffnn_model.pth&#39;</span>))</span>
<span id="cb86-4"><a href="#cb86-4" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">eval</span>() <span class="co"># Set to evaluation mode</span></span></code></pre></div>
</div>
</body>
</html>
